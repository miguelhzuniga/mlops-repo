[2025-04-01T18:05:54.681+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-01T18:05:54.717+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 4-Procesa_data.experimentos_task manual__2025-04-01T18:03:50.676726+00:00 [queued]>
[2025-04-01T18:05:54.730+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 4-Procesa_data.experimentos_task manual__2025-04-01T18:03:50.676726+00:00 [queued]>
[2025-04-01T18:05:54.730+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 1
[2025-04-01T18:05:54.750+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): experimentos_task> on 2025-04-01 18:03:50.676726+00:00
[2025-04-01T18:05:54.774+0000] {standard_task_runner.py:72} INFO - Started process 441 to run task
[2025-04-01T18:05:54.786+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', '4-Procesa_data', 'experimentos_task', 'manual__2025-04-01T18:03:50.676726+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/Procesa_data.py', '--cfg-path', '/tmp/tmppaye1e22']
[2025-04-01T18:05:54.793+0000] {standard_task_runner.py:105} INFO - Job 12: Subtask experimentos_task
[2025-04-01T18:05:54.894+0000] {task_command.py:467} INFO - Running <TaskInstance: 4-Procesa_data.experimentos_task manual__2025-04-01T18:03:50.676726+00:00 [running]> on host 111d26a6d12f
[2025-04-01T18:05:55.061+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='4-Procesa_data' AIRFLOW_CTX_TASK_ID='experimentos_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-01T18:03:50.676726+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-04-01T18:03:50.676726+00:00'
[2025-04-01T18:05:55.063+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-01T18:05:55.117+0000] {warnings.py:109} WARNING - /opt/***/dags/Procesa_data.py:67: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query, conn)

[2025-04-01T18:05:57.070+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:05:57 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2025-04-01T18:05:57.141+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:05:57 WARNING mlflow.utils: Truncated the value of the key `estimator`. Truncated value: `Pipeline(steps=[('column_trans',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('onehotencoder',
                                                  OneHotEncoder(handle_unknown='ignore'),
                                                  ['Wilderness_Area',
                                                   'Soil_Type'])])),
                ('scaler', StandardScaler(with_mean=False)),
                ('RandomForestClassifier', Rand...`
[2025-04-01T18:05:57.155+0000] {logging_and_warnings.py:72} WARNING - /home/***/.local/lib/python3.8/site-packages/joblib/parallel.py:1359: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,

[2025-04-01T18:06:37.000+0000] {credentials.py:1147} INFO - Found credentials in environment variables.
[2025-04-01T18:06:38.002+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:06:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/home/***/.local/lib/python3.8/site-packages/mlflow/models/signature.py:137: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details."
[2025-04-01T18:06:50.449+0000] {logging_mixin.py:190} WARNING - Registered model 'modelo1' already exists. Creating a new version of this model...
[2025-04-01T18:06:50.491+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:06:50 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: modelo1, version 3
[2025-04-01T18:06:50.493+0000] {logging_mixin.py:190} WARNING - Created version '3' of model 'modelo1'.
[2025-04-01T18:06:54.783+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:06:54 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.
[2025-04-01T18:06:55.596+0000] {logging_mixin.py:190} INFO - Experimento registrado correctamente.
[2025-04-01T18:06:55.621+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-01T18:06:55.659+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-01T18:06:55.660+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=4-Procesa_data, task_id=experimentos_task, run_id=manual__2025-04-01T18:03:50.676726+00:00, execution_date=20250401T180350, start_date=20250401T180554, end_date=20250401T180655
[2025-04-01T18:06:55.924+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-01T18:06:55.978+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-01T18:06:55.980+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
