[2025-04-01T07:23:39.962+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-01T07:23:40.049+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 4-Procesa_data.experimentos_task scheduled__2025-03-31T00:00:00+00:00 [queued]>
[2025-04-01T07:23:40.088+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 4-Procesa_data.experimentos_task scheduled__2025-03-31T00:00:00+00:00 [queued]>
[2025-04-01T07:23:40.091+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 1
[2025-04-01T07:23:40.132+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): experimentos_task> on 2025-03-31 00:00:00+00:00
[2025-04-01T07:23:40.170+0000] {standard_task_runner.py:72} INFO - Started process 399 to run task
[2025-04-01T07:23:40.189+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', '4-Procesa_data', 'experimentos_task', 'scheduled__2025-03-31T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/Procesa_data.py', '--cfg-path', '/tmp/tmp0aggv4se']
[2025-04-01T07:23:40.197+0000] {standard_task_runner.py:105} INFO - Job 9: Subtask experimentos_task
[2025-04-01T07:23:40.356+0000] {task_command.py:467} INFO - Running <TaskInstance: 4-Procesa_data.experimentos_task scheduled__2025-03-31T00:00:00+00:00 [running]> on host f06b106b6cde
[2025-04-01T07:23:40.659+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='4-Procesa_data' AIRFLOW_CTX_TASK_ID='experimentos_task' AIRFLOW_CTX_EXECUTION_DATE='2025-03-31T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-03-31T00:00:00+00:00'
[2025-04-01T07:23:40.661+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-01T07:23:40.822+0000] {warnings.py:109} WARNING - /opt/***/dags/Procesa_data.py:61: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query, conn)

[2025-04-01T07:23:44.433+0000] {logging_mixin.py:190} WARNING - 2025/04/01 07:23:44 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2025-04-01T07:23:44.711+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/Procesa_data.py", line 96, in experimentar
    rf.fit(X_train, y_train)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 554, in safe_patch_function
    patch_function(call_original, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 254, in patch_with_managed_run
    result = patch_function(original, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/sklearn/__init__.py", line 1580, in patched_fit
    result = fit_impl(original, self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/sklearn/__init__.py", line 1368, in fit_mlflow
    fit_output = original(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 535, in call_original
    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 470, in call_original_fn_with_event_logging
    original_fn_result = original_fn(*og_args, **og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 532, in _original_fn
    original_result = original(*_og_args, **_og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py", line 327, in fit
    X, y = self._validate_data(
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/base.py", line 581, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 964, in check_X_y
    X = check_array(
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 746, in check_array
    array = np.asarray(array, order=order, dtype=dtype)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 1998, in __array__
    arr = np.asarray(values, dtype=dtype)
ValueError: could not convert string to float: 'Commanche'
[2025-04-01T07:23:44.764+0000] {taskinstance.py:1226} INFO - Marking task as FAILED. dag_id=4-Procesa_data, task_id=experimentos_task, run_id=scheduled__2025-03-31T00:00:00+00:00, execution_date=20250331T000000, start_date=20250401T072340, end_date=20250401T072344
[2025-04-01T07:23:44.855+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-01T07:23:44.857+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 9 for task experimentos_task (could not convert string to float: 'Commanche'; 399)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/Procesa_data.py", line 96, in experimentar
    rf.fit(X_train, y_train)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 554, in safe_patch_function
    patch_function(call_original, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 254, in patch_with_managed_run
    result = patch_function(original, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/sklearn/__init__.py", line 1580, in patched_fit
    result = fit_impl(original, self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/sklearn/__init__.py", line 1368, in fit_mlflow
    fit_output = original(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 535, in call_original
    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 470, in call_original_fn_with_event_logging
    original_fn_result = original_fn(*og_args, **og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 532, in _original_fn
    original_result = original(*_og_args, **_og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py", line 327, in fit
    X, y = self._validate_data(
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/base.py", line 581, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 964, in check_X_y
    X = check_array(
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 746, in check_array
    array = np.asarray(array, order=order, dtype=dtype)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 1998, in __array__
    arr = np.asarray(values, dtype=dtype)
ValueError: could not convert string to float: 'Commanche'
[2025-04-01T07:23:44.985+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-01T07:23:45.030+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-01T07:23:45.034+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-01T17:06:32.531+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-01T17:06:32.561+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 4-Procesa_data.experimentos_task scheduled__2025-03-31T00:00:00+00:00 [queued]>
[2025-04-01T17:06:32.573+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 4-Procesa_data.experimentos_task scheduled__2025-03-31T00:00:00+00:00 [queued]>
[2025-04-01T17:06:32.574+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 1
[2025-04-01T17:06:32.594+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): experimentos_task> on 2025-03-31 00:00:00+00:00
[2025-04-01T17:06:32.619+0000] {standard_task_runner.py:72} INFO - Started process 409 to run task
[2025-04-01T17:06:32.630+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', '4-Procesa_data', 'experimentos_task', 'scheduled__2025-03-31T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/Procesa_data.py', '--cfg-path', '/tmp/tmpjuwpr2l0']
[2025-04-01T17:06:32.638+0000] {standard_task_runner.py:105} INFO - Job 9: Subtask experimentos_task
[2025-04-01T17:06:32.754+0000] {task_command.py:467} INFO - Running <TaskInstance: 4-Procesa_data.experimentos_task scheduled__2025-03-31T00:00:00+00:00 [running]> on host 56b31014e3cf
[2025-04-01T17:06:32.903+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='4-Procesa_data' AIRFLOW_CTX_TASK_ID='experimentos_task' AIRFLOW_CTX_EXECUTION_DATE='2025-03-31T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-03-31T00:00:00+00:00'
[2025-04-01T17:06:32.905+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-01T17:06:32.949+0000] {warnings.py:109} WARNING - /opt/***/dags/Procesa_data.py:61: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query, conn)

[2025-04-01T17:06:33.935+0000] {logging_mixin.py:190} WARNING - 2025/04/01 17:06:33 INFO mlflow.tracking.fluent: Experiment with name 'mlflow_tracking_examples' does not exist. Creating a new experiment.
[2025-04-01T17:06:35.633+0000] {logging_mixin.py:190} WARNING - 2025/04/01 17:06:35 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2025-04-01T17:06:36.050+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/Procesa_data.py", line 96, in experimentar
    rf.fit(X_train, y_train)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 554, in safe_patch_function
    patch_function(call_original, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 254, in patch_with_managed_run
    result = patch_function(original, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/sklearn/__init__.py", line 1580, in patched_fit
    result = fit_impl(original, self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/sklearn/__init__.py", line 1368, in fit_mlflow
    fit_output = original(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 535, in call_original
    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 470, in call_original_fn_with_event_logging
    original_fn_result = original_fn(*og_args, **og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 532, in _original_fn
    original_result = original(*_og_args, **_og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py", line 327, in fit
    X, y = self._validate_data(
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/base.py", line 581, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 964, in check_X_y
    X = check_array(
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 746, in check_array
    array = np.asarray(array, order=order, dtype=dtype)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 1998, in __array__
    arr = np.asarray(values, dtype=dtype)
ValueError: could not convert string to float: 'Neota'
[2025-04-01T17:06:36.148+0000] {taskinstance.py:1226} INFO - Marking task as FAILED. dag_id=4-Procesa_data, task_id=experimentos_task, run_id=scheduled__2025-03-31T00:00:00+00:00, execution_date=20250331T000000, start_date=20250401T170632, end_date=20250401T170636
[2025-04-01T17:06:36.230+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-01T17:06:36.231+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 9 for task experimentos_task (could not convert string to float: 'Neota'; 409)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/Procesa_data.py", line 96, in experimentar
    rf.fit(X_train, y_train)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 554, in safe_patch_function
    patch_function(call_original, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 254, in patch_with_managed_run
    result = patch_function(original, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/sklearn/__init__.py", line 1580, in patched_fit
    result = fit_impl(original, self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/sklearn/__init__.py", line 1368, in fit_mlflow
    fit_output = original(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 535, in call_original
    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 470, in call_original_fn_with_event_logging
    original_fn_result = original_fn(*og_args, **og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py", line 532, in _original_fn
    original_result = original(*_og_args, **_og_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py", line 327, in fit
    X, y = self._validate_data(
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/base.py", line 581, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 964, in check_X_y
    X = check_array(
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 746, in check_array
    array = np.asarray(array, order=order, dtype=dtype)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 1998, in __array__
    arr = np.asarray(values, dtype=dtype)
ValueError: could not convert string to float: 'Neota'
[2025-04-01T17:06:36.331+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-01T17:06:36.375+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-01T17:06:36.377+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-01T18:03:56.014+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-01T18:03:56.044+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 4-Procesa_data.experimentos_task scheduled__2025-03-31T00:00:00+00:00 [queued]>
[2025-04-01T18:03:56.055+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 4-Procesa_data.experimentos_task scheduled__2025-03-31T00:00:00+00:00 [queued]>
[2025-04-01T18:03:56.056+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 1
[2025-04-01T18:03:56.072+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): experimentos_task> on 2025-03-31 00:00:00+00:00
[2025-04-01T18:03:56.102+0000] {standard_task_runner.py:72} INFO - Started process 238 to run task
[2025-04-01T18:03:56.117+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', '4-Procesa_data', 'experimentos_task', 'scheduled__2025-03-31T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/Procesa_data.py', '--cfg-path', '/tmp/tmprtp13hqw']
[2025-04-01T18:03:56.129+0000] {standard_task_runner.py:105} INFO - Job 8: Subtask experimentos_task
[2025-04-01T18:03:56.278+0000] {task_command.py:467} INFO - Running <TaskInstance: 4-Procesa_data.experimentos_task scheduled__2025-03-31T00:00:00+00:00 [running]> on host 111d26a6d12f
[2025-04-01T18:03:56.513+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='4-Procesa_data' AIRFLOW_CTX_TASK_ID='experimentos_task' AIRFLOW_CTX_EXECUTION_DATE='2025-03-31T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-03-31T00:00:00+00:00'
[2025-04-01T18:03:56.518+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-01T18:03:56.645+0000] {warnings.py:109} WARNING - /opt/***/dags/Procesa_data.py:67: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query, conn)

[2025-04-01T18:03:59.725+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:03:59 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2025-04-01T18:03:59.837+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:03:59 WARNING mlflow.utils: Truncated the value of the key `estimator`. Truncated value: `Pipeline(steps=[('column_trans',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('onehotencoder',
                                                  OneHotEncoder(handle_unknown='ignore'),
                                                  ['Wilderness_Area',
                                                   'Soil_Type'])])),
                ('scaler', StandardScaler(with_mean=False)),
                ('RandomForestClassifier', Rand...`
[2025-04-01T18:03:59.864+0000] {logging_and_warnings.py:72} WARNING - /home/***/.local/lib/python3.8/site-packages/joblib/parallel.py:1359: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,

[2025-04-01T18:04:20.216+0000] {credentials.py:1147} INFO - Found credentials in environment variables.
[2025-04-01T18:04:55.861+0000] {job.py:229} INFO - Heartbeat recovered after 21.02 seconds
[2025-04-01T18:04:56.871+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:04:56 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/home/***/.local/lib/python3.8/site-packages/mlflow/models/signature.py:137: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details."
[2025-04-01T18:05:36.648+0000] {logging_mixin.py:190} WARNING - Registered model 'modelo1' already exists. Creating a new version of this model...
[2025-04-01T18:05:36.715+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:05:36 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: modelo1, version 2
[2025-04-01T18:05:36.716+0000] {logging_mixin.py:190} WARNING - Created version '2' of model 'modelo1'.
[2025-04-01T18:05:45.812+0000] {logging_mixin.py:190} WARNING - 2025/04/01 18:05:45 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.
[2025-04-01T18:05:47.160+0000] {logging_mixin.py:190} INFO - Experimento registrado correctamente.
[2025-04-01T18:05:47.183+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-01T18:05:47.247+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-01T18:05:47.248+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=4-Procesa_data, task_id=experimentos_task, run_id=scheduled__2025-03-31T00:00:00+00:00, execution_date=20250331T000000, start_date=20250401T180356, end_date=20250401T180547
[2025-04-01T18:05:47.545+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-01T18:05:47.613+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-01T18:05:47.615+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
