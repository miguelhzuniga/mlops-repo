[2025-04-02T00:00:25.850+0000] {processor.py:186} INFO - Started process (PID=13024) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:00:25.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:00:25.865+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:00:25.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:02:15.176+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:00:57.708+0000] {timeout.py:68} ERROR - Process timed out, PID: 13024
[2025-04-02T00:02:58.234+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:02:22.217+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 3, in <module>
    from sklearn.model_selection import train_test_split
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/__init__.py", line 82, in <module>
    from .base import clone
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/base.py", line 17, in <module>
    from .utils import _IS_32BIT
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/__init__.py", line 28, in <module>
    from .fixes import np_version, parse_version
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py", line 20, in <module>
    import scipy.stats
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/stats/__init__.py", line 485, in <module>
    from ._stats_py import *
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/stats/_stats_py.py", line 46, in <module>
    from . import distributions
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/stats/distributions.py", line 8, in <module>
    from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen)
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py", line 22, in <module>
    from scipy import optimize
  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/__init__.py", line 200, in __getattr__
    return _importlib.import_module(f'scipy.{name}')
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/optimize/__init__.py", line 404, in <module>
    from ._optimize import *
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py", line 38, in <module>
    from ._hessian_update_strategy import HessianUpdateStrategy
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/optimize/_hessian_update_strategy.py", line 103, in <module>
    class FullHessianUpdateStrategy(HessianUpdateStrategy):
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/optimize/_hessian_update_strategy.py", line 107, in FullHessianUpdateStrategy
    _syr2 = get_blas_funcs('syr2', dtype='d')  # Symmetric rank 2 update
  File "/home/airflow/.local/lib/python3.8/site-packages/scipy/linalg/blas.py", line 387, in getter
    for array in arrays:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13024
[2025-04-02T00:03:02.316+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:03:40.242+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-04-02T00:06:19.713+0000] {processor.py:186} INFO - Started process (PID=13034) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:06:19.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:06:19.812+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:06:19.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:06:50.329+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:06:50.044+0000] {timeout.py:68} ERROR - Process timed out, PID: 13034
[2025-04-02T00:06:51.387+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:06:50.390+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/posixpath.py", line 177, in lexists
    os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/home/airflow/.local/lib/python3.8/site-packages/grpc_google_iam_v1-0.14.0.dist-info/entry_points.txt'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 20, in <module>
    from mlflow.tracking.fluent import _EXPERIMENT_ID_ENV_VAR, _EXPERIMENT_NAME_ENV_VAR, _RUN_ID_ENV_VAR
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/fluent.py", line 22, in <module>
    from mlflow.tracking.context import registry as context_registry
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/context/registry.py", line 63, in <module>
    _run_context_provider_registry.register_entrypoints()
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/context/registry.py", line 38, in register_entrypoints
    for entrypoint in entrypoints.get_group_all("mlflow.run_context_provider"):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 237, in get_group_all
    for config, distro in iter_files_distros(path=path):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 190, in iter_files_distros
    for path in itertools.chain(
  File "/usr/local/lib/python3.8/glob.py", line 74, in _iglob
    for name in glob_in_dir(dirname, basename, dironly):
  File "/usr/local/lib/python3.8/glob.py", line 94, in _glob0
    if os.path.lexists(os.path.join(dirname, basename)):
  File "/usr/local/lib/python3.8/posixpath.py", line 177, in lexists
    os.lstat(path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13034
[2025-04-02T00:06:51.403+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:07:09.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 49.969 seconds
[2025-04-02T00:07:43.066+0000] {processor.py:186} INFO - Started process (PID=13045) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:07:43.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:07:43.241+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:07:43.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:08:14.123+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:08:13.727+0000] {timeout.py:68} ERROR - Process timed out, PID: 13045
[2025-04-02T00:08:17.120+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:08:14.528+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 8, in <module>
    from mlflow.tracking.client import MlflowClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/client.py", line 27, in <module>
    from mlflow.tracking._model_registry.client import ModelRegistryClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_model_registry/client.py", line 18, in <module>
    from mlflow.tracking._model_registry import utils, DEFAULT_AWAIT_MAX_SLEEP_SECONDS
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_model_registry/utils.py", line 10, in <module>
    from mlflow.tracking._tracking_service.utils import (
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/utils.py", line 213, in <module>
    _tracking_store_registry.register_entrypoints()
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/registry.py", line 52, in register_entrypoints
    for entrypoint in entrypoints.get_group_all(self.group_name):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 237, in get_group_all
    for config, distro in iter_files_distros(path=path):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 190, in iter_files_distros
    for path in itertools.chain(
  File "/usr/local/lib/python3.8/glob.py", line 74, in _iglob
    for name in glob_in_dir(dirname, basename, dironly):
  File "/usr/local/lib/python3.8/glob.py", line 94, in _glob0
    if os.path.lexists(os.path.join(dirname, basename)):
  File "/usr/local/lib/python3.8/posixpath.py", line 177, in lexists
    os.lstat(path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13045
[2025-04-02T00:08:17.703+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:08:41.472+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-04-02T00:09:21.832+0000] {processor.py:186} INFO - Started process (PID=13062) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:09:21.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:09:21.913+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:09:21.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:09:52.542+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:09:52.407+0000] {timeout.py:68} ERROR - Process timed out, PID: 13062
[2025-04-02T00:09:53.225+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:09:52.563+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 28, in <module>
    from mlflow.projects.backend import loader
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/backend/loader.py", line 4, in <module>
    from mlflow.projects.backend.local import LocalBackend
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/backend/local.py", line 32, in <module>
    from mlflow.utils.virtualenv import (
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/virtualenv.py", line 11, in <module>
    from mlflow.models.model import Model, MLMODEL_FILE_NAME
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/models/__init__.py", line 98, in <module>
    from .signature import ModelSignature, infer_signature  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/models/signature.py", line 13, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 48, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/api.py", line 27, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/__init__.py", line 8, in <module>
    from pandas.core.arrays.categorical import Categorical
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/categorical.py", line 27, in <module>
    from pandas._libs.arrays import NDArrayBacked
  File "<frozen importlib._bootstrap>", line 389, in parent
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13062
[2025-04-02T00:09:53.445+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:10:06.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 44.788 seconds
[2025-04-02T00:10:42.398+0000] {processor.py:186} INFO - Started process (PID=13075) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:10:42.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:10:42.587+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:10:42.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:11:15.701+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:11:15.279+0000] {timeout.py:68} ERROR - Process timed out, PID: 13075
[2025-04-02T00:11:25.467+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:11:16.139+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 8, in <module>
    from mlflow.tracking.client import MlflowClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/client.py", line 27, in <module>
    from mlflow.tracking._model_registry.client import ModelRegistryClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_model_registry/client.py", line 18, in <module>
    from mlflow.tracking._model_registry import utils, DEFAULT_AWAIT_MAX_SLEEP_SECONDS
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_model_registry/utils.py", line 6, in <module>
    from mlflow.store.model_registry.file_store import FileStore
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/model_registry/file_store.py", line 47, in <module>
    from mlflow.utils.file_utils import (
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/file_utils.py", line 38, in <module>
    from mlflow.utils.databricks_utils import _get_dbutils
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/databricks_utils.py", line 10, in <module>
    from mlflow.utils._spark_utils import _get_active_spark_session
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 934, in get_code
  File "<frozen importlib._bootstrap_external>", line 1032, in get_data
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13075
[2025-04-02T00:11:51.086+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:12:11.780+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-04-02T00:13:03.445+0000] {processor.py:186} INFO - Started process (PID=13079) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:13:03.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:13:03.521+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:13:03.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:13:41.479+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:13:41.293+0000] {timeout.py:68} ERROR - Process timed out, PID: 13079
[2025-04-02T00:13:42.147+0000] {logging_mixin.py:190} WARNING - Exception ignored in: <function _collection_gced at 0x7ae8fc78d5e0>
[2025-04-02T00:13:42.805+0000] {logging_mixin.py:190} WARNING - Traceback (most recent call last):
[2025-04-02T00:13:43.444+0000] {logging_mixin.py:190} WARNING -   File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/event/registry.py", line 53, in _collection_gced
[2025-04-02T00:13:45.730+0000] {logging_mixin.py:190} WARNING -     def _collection_gced(ref):
[2025-04-02T00:13:46.682+0000] {logging_mixin.py:190} WARNING -   File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
[2025-04-02T00:13:46.765+0000] {logging_mixin.py:190} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2025-04-02T00:13:46.766+0000] {logging_mixin.py:190} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13079
[2025-04-02T00:14:22.801+0000] {processor.py:186} INFO - Started process (PID=13105) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:14:22.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:14:22.863+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:14:22.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:14:53.043+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:14:53.036+0000] {timeout.py:68} ERROR - Process timed out, PID: 13105
[2025-04-02T00:14:53.113+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:14:53.054+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 20, in <module>
    from mlflow.tracking.fluent import _EXPERIMENT_ID_ENV_VAR, _EXPERIMENT_NAME_ENV_VAR, _RUN_ID_ENV_VAR
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/fluent.py", line 26, in <module>
    from mlflow.utils.autologging_utils import (
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/utils/autologging_utils/__init__.py", line 38, in <module>
    from mlflow.utils.autologging_utils.client import *
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 934, in get_code
  File "<frozen importlib._bootstrap_external>", line 1033, in get_data
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13105
[2025-04-02T00:14:53.129+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:14:54.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 31.759 seconds
[2025-04-02T00:15:25.215+0000] {processor.py:186} INFO - Started process (PID=13126) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:15:25.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:15:25.299+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:15:25.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:15:59.375+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:15:56.229+0000] {timeout.py:68} ERROR - Process timed out, PID: 13126
[2025-04-02T00:16:15.581+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:15:59.686+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/posixpath.py", line 177, in lexists
    os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/home/airflow/.local/lib/python3.8/site-packages/tzdata-2025.1.dist-info/entry_points.txt'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 8, in <module>
    from mlflow.tracking.client import MlflowClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/client.py", line 31, in <module>
    from mlflow.tracking._tracking_service.client import TrackingServiceClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py", line 21, in <module>
    from mlflow.store.artifact.artifact_repository_registry import get_artifact_repository
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/artifact/artifact_repository_registry.py", line 93, in <module>
    _artifact_repository_registry.register_entrypoints()
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/artifact/artifact_repository_registry.py", line 42, in register_entrypoints
    for entrypoint in entrypoints.get_group_all("mlflow.artifact_repository"):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 237, in get_group_all
    for config, distro in iter_files_distros(path=path):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 190, in iter_files_distros
    for path in itertools.chain(
  File "/usr/local/lib/python3.8/glob.py", line 74, in _iglob
    for name in glob_in_dir(dirname, basename, dironly):
  File "/usr/local/lib/python3.8/glob.py", line 94, in _glob0
    if os.path.lexists(os.path.join(dirname, basename)):
  File "/usr/local/lib/python3.8/posixpath.py", line 177, in lexists
    os.lstat(path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13126
[2025-04-02T00:16:15.823+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:16:49.671+0000] {processor.py:186} INFO - Started process (PID=13137) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:16:49.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:16:49.708+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:16:49.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:17:19.768+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:17:19.743+0000] {timeout.py:68} ERROR - Process timed out, PID: 13137
[2025-04-02T00:17:19.892+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:17:19.784+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 20, in <module>
    from mlflow.tracking.fluent import _EXPERIMENT_ID_ENV_VAR, _EXPERIMENT_NAME_ENV_VAR, _RUN_ID_ENV_VAR
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/fluent.py", line 22, in <module>
    from mlflow.tracking.context import registry as context_registry
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/context/registry.py", line 63, in <module>
    _run_context_provider_registry.register_entrypoints()
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/context/registry.py", line 38, in register_entrypoints
    for entrypoint in entrypoints.get_group_all("mlflow.run_context_provider"):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 237, in get_group_all
    for config, distro in iter_files_distros(path=path):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 190, in iter_files_distros
    for path in itertools.chain(
  File "/usr/local/lib/python3.8/glob.py", line 74, in _iglob
    for name in glob_in_dir(dirname, basename, dironly):
  File "/usr/local/lib/python3.8/glob.py", line 94, in _glob0
    if os.path.lexists(os.path.join(dirname, basename)):
  File "/usr/local/lib/python3.8/posixpath.py", line 177, in lexists
    os.lstat(path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13137
[2025-04-02T00:17:19.905+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:17:20.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 31.533 seconds
[2025-04-02T00:17:52.426+0000] {processor.py:186} INFO - Started process (PID=13155) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:17:52.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:17:52.566+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:17:52.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:18:24.024+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:18:23.344+0000] {timeout.py:68} ERROR - Process timed out, PID: 13155
[2025-04-02T00:18:29.856+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:18:24.484+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 20, in <module>
    from mlflow.tracking.fluent import _EXPERIMENT_ID_ENV_VAR, _EXPERIMENT_NAME_ENV_VAR, _RUN_ID_ENV_VAR
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/fluent.py", line 22, in <module>
    from mlflow.tracking.context import registry as context_registry
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/context/registry.py", line 63, in <module>
    _run_context_provider_registry.register_entrypoints()
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/context/registry.py", line 38, in register_entrypoints
    for entrypoint in entrypoints.get_group_all("mlflow.run_context_provider"):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 237, in get_group_all
    for config, distro in iter_files_distros(path=path):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 190, in iter_files_distros
    for path in itertools.chain(
  File "/usr/local/lib/python3.8/glob.py", line 74, in _iglob
    for name in glob_in_dir(dirname, basename, dironly):
  File "/usr/local/lib/python3.8/glob.py", line 94, in _glob0
    if os.path.lexists(os.path.join(dirname, basename)):
  File "/usr/local/lib/python3.8/posixpath.py", line 177, in lexists
    os.lstat(path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13155
[2025-04-02T00:18:29.947+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:18:51.444+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-04-02T00:19:28.377+0000] {processor.py:186} INFO - Started process (PID=13167) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:19:28.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:19:28.384+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:19:28.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:20:00.623+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:19:58.876+0000] {timeout.py:68} ERROR - Process timed out, PID: 13167
[2025-04-02T00:20:03.936+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:20:02.078+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 20, in <module>
    from mlflow.tracking.fluent import _EXPERIMENT_ID_ENV_VAR, _EXPERIMENT_NAME_ENV_VAR, _RUN_ID_ENV_VAR
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/fluent.py", line 23, in <module>
    from mlflow.tracking.default_experiment import registry as default_experiment_registry
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/default_experiment/registry.py", line 62, in <module>
    _default_experiment_provider_registry.register_entrypoints()
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/default_experiment/registry.py", line 44, in register_entrypoints
    for entrypoint in entrypoints.get_group_all("mlflow.default_experiment_provider"):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 237, in get_group_all
    for config, distro in iter_files_distros(path=path):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 190, in iter_files_distros
    for path in itertools.chain(
  File "/usr/local/lib/python3.8/glob.py", line 73, in _iglob
    for dirname in dirs:
  File "/usr/local/lib/python3.8/glob.py", line 74, in _iglob
    for name in glob_in_dir(dirname, basename, dironly):
  File "/usr/local/lib/python3.8/glob.py", line 82, in _glob1
    names = list(_iterdir(dirname, dironly))
  File "/usr/local/lib/python3.8/glob.py", line 124, in _iterdir
    for entry in it:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13167
[2025-04-02T00:20:04.581+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:20:57.674+0000] {processor.py:186} INFO - Started process (PID=13185) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:20:57.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:20:57.804+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:20:57.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:21:31.170+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:21:28.267+0000] {timeout.py:68} ERROR - Process timed out, PID: 13185
[2025-04-02T00:21:36.784+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:21:32.254+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 20, in <module>
    from mlflow.tracking.fluent import _EXPERIMENT_ID_ENV_VAR, _EXPERIMENT_NAME_ENV_VAR, _RUN_ID_ENV_VAR
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/fluent.py", line 22, in <module>
    from mlflow.tracking.context import registry as context_registry
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/context/registry.py", line 63, in <module>
    _run_context_provider_registry.register_entrypoints()
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/context/registry.py", line 38, in register_entrypoints
    for entrypoint in entrypoints.get_group_all("mlflow.run_context_provider"):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 237, in get_group_all
    for config, distro in iter_files_distros(path=path):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 202, in iter_files_distros
    cp = CaseSensitiveConfigParser(delimiters=('=',))
  File "/usr/local/lib/python3.8/configparser.py", line 611, in __init__
    self._converters = ConverterMapping(self)
  File "/usr/local/lib/python3.8/configparser.py", line 1321, in __init__
    m = self.GETTERCRE.match(getter)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13185
[2025-04-02T00:21:38.719+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:22:20.125+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-04-02T00:24:55.888+0000] {processor.py:186} INFO - Started process (PID=13196) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:24:55.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:24:55.896+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:24:55.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:25:27.192+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:25:26.304+0000] {timeout.py:68} ERROR - Process timed out, PID: 13196
[2025-04-02T00:25:33.414+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:25:29.388+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 8, in <module>
    from mlflow.tracking.client import MlflowClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/client.py", line 31, in <module>
    from mlflow.tracking._tracking_service.client import TrackingServiceClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py", line 21, in <module>
    from mlflow.store.artifact.artifact_repository_registry import get_artifact_repository
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/artifact/artifact_repository_registry.py", line 7, in <module>
    from mlflow.store.artifact.ftp_artifact_repo import FTPArtifactRepository
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/artifact/ftp_artifact_repo.py", line 2, in <module>
    import ftplib
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13196
[2025-04-02T00:25:34.444+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:25:57.211+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-04-02T00:28:55.357+0000] {processor.py:186} INFO - Started process (PID=13200) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:28:55.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:28:55.401+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:28:55.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:29:27.460+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:29:25.940+0000] {timeout.py:68} ERROR - Process timed out, PID: 13200
[2025-04-02T00:29:29.823+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:29:27.642+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 1, in <module>
    import mlflow
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/__init__.py", line 41, in <module>
    from mlflow import projects  # pylint: disable=unused-import
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/__init__.py", line 9, in <module>
    import mlflow.projects.databricks
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/projects/databricks.py", line 12, in <module>
    from mlflow import tracking
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/__init__.py", line 8, in <module>
    from mlflow.tracking.client import MlflowClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/client.py", line 31, in <module>
    from mlflow.tracking._tracking_service.client import TrackingServiceClient
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py", line 21, in <module>
    from mlflow.store.artifact.artifact_repository_registry import get_artifact_repository
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/artifact/artifact_repository_registry.py", line 93, in <module>
    _artifact_repository_registry.register_entrypoints()
  File "/home/airflow/.local/lib/python3.8/site-packages/mlflow/store/artifact/artifact_repository_registry.py", line 42, in register_entrypoints
    for entrypoint in entrypoints.get_group_all("mlflow.artifact_repository"):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 237, in get_group_all
    for config, distro in iter_files_distros(path=path):
  File "/home/airflow/.local/lib/python3.8/site-packages/entrypoints.py", line 190, in iter_files_distros
    for path in itertools.chain(
  File "/usr/local/lib/python3.8/glob.py", line 74, in _iglob
    for name in glob_in_dir(dirname, basename, dironly):
  File "/usr/local/lib/python3.8/glob.py", line 94, in _glob0
    if os.path.lexists(os.path.join(dirname, basename)):
  File "/usr/local/lib/python3.8/posixpath.py", line 177, in lexists
    os.lstat(path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13200
[2025-04-02T00:29:31.809+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:29:54.573+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-04-02T00:34:02.107+0000] {processor.py:186} INFO - Started process (PID=13211) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:34:02.117+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:34:02.132+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:34:02.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:40:14.609+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:34:40.955+0000] {timeout.py:68} ERROR - Process timed out, PID: 13211
[2025-04-02T00:42:35.819+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:40:16.664+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/Procesa_data.py
Traceback (most recent call last):
  File "<frozen importlib._bootstrap_external>", line 1346, in _path_importer_cache
KeyError: '/home/airflow/.local/lib/python3.8/site-packages/joblib'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Procesa_data.py", line 3, in <module>
    from sklearn.model_selection import train_test_split
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/__init__.py", line 82, in <module>
    from .base import clone
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/base.py", line 17, in <module>
    from .utils import _IS_32BIT
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/__init__.py", line 25, in <module>
    from . import _joblib
  File "/home/airflow/.local/lib/python3.8/site-packages/sklearn/utils/_joblib.py", line 7, in <module>
    import joblib
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/__init__.py", line 114, in <module>
    from .memory import Memory
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 914, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1407, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1376, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1346, in _path_importer_cache
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Procesa_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.5/best-practices.html#reducing-dag-complexity, PID: 13211
[2025-04-02T00:42:35.922+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:43:08.804+0000] {processor.py:186} INFO - Started process (PID=13235) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:43:08.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:43:08.848+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:43:08.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:43:21.293+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:43:22.318+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:43:22.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:43:22.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 13.913 seconds
[2025-04-02T00:43:53.234+0000] {processor.py:186} INFO - Started process (PID=13259) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:43:53.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:43:53.257+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:43:53.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:44:01.662+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:44:01.821+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:44:01.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:44:01.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 8.843 seconds
[2025-04-02T00:44:32.961+0000] {processor.py:186} INFO - Started process (PID=13277) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:44:32.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:44:32.967+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:44:32.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:44:37.415+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:44:37.459+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:44:37.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:44:37.499+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:44:37.499+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:44:37.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.623 seconds
[2025-04-02T00:45:08.076+0000] {processor.py:186} INFO - Started process (PID=13296) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:45:08.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:45:08.092+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:45:08.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:45:13.378+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:45:13.466+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:45:13.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:45:13.556+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:45:13.556+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:45:13.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 5.604 seconds
[2025-04-02T00:45:44.794+0000] {processor.py:186} INFO - Started process (PID=13315) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:45:44.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:45:44.820+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:45:44.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:45:49.182+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:45:49.325+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:45:49.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:45:49.390+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:45:49.389+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:45:49.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.811 seconds
[2025-04-02T00:46:19.666+0000] {processor.py:186} INFO - Started process (PID=13340) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:46:19.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:46:19.671+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:46:19.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:46:23.091+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:46:23.147+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:46:23.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:46:23.200+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:46:23.199+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:46:23.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.598 seconds
[2025-04-02T00:46:54.177+0000] {processor.py:186} INFO - Started process (PID=13359) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:46:54.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:46:54.182+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:46:54.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:46:58.502+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:46:58.563+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:46:58.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:46:58.612+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:46:58.611+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:46:58.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.494 seconds
[2025-04-02T00:47:29.205+0000] {processor.py:186} INFO - Started process (PID=13379) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:47:29.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:47:29.210+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:47:29.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:47:31.512+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:47:31.581+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:47:31.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:47:31.624+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:47:31.624+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:47:31.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.468 seconds
[2025-04-02T00:48:02.447+0000] {processor.py:186} INFO - Started process (PID=13398) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:48:02.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:48:02.452+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:48:02.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:48:04.661+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:48:04.715+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:48:04.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:48:04.765+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:48:04.765+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:48:04.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.370 seconds
[2025-04-02T00:48:35.188+0000] {processor.py:186} INFO - Started process (PID=13419) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:48:35.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:48:35.195+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:48:35.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:48:37.450+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:48:37.505+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:48:37.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:48:37.551+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:48:37.551+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:48:37.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.413 seconds
[2025-04-02T00:49:07.843+0000] {processor.py:186} INFO - Started process (PID=13438) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:49:07.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:49:07.847+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:49:07.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:49:09.827+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:49:09.882+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:49:09.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:49:09.926+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:49:09.925+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:49:09.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.145 seconds
[2025-04-02T00:49:40.261+0000] {processor.py:186} INFO - Started process (PID=13457) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:49:40.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:49:40.265+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:49:40.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:49:42.216+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:49:42.259+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:49:42.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:49:42.298+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:49:42.298+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:49:42.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.079 seconds
[2025-04-02T00:50:12.621+0000] {processor.py:186} INFO - Started process (PID=13475) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:50:12.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:50:12.627+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:50:12.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:50:14.644+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:50:14.687+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:50:14.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:50:14.723+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:50:14.722+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:50:14.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.150 seconds
[2025-04-02T00:50:45.105+0000] {processor.py:186} INFO - Started process (PID=13493) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:50:45.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:50:45.110+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:50:45.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:50:47.126+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:50:47.195+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:50:47.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:50:47.242+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:50:47.241+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:50:47.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.193 seconds
[2025-04-02T00:51:17.735+0000] {processor.py:186} INFO - Started process (PID=13512) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:51:17.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:51:17.741+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:51:17.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:51:19.730+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:51:19.797+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:51:19.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:51:19.880+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:51:19.877+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:51:19.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.213 seconds
[2025-04-02T00:51:50.450+0000] {processor.py:186} INFO - Started process (PID=13537) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:51:50.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:51:50.470+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:51:50.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:51:52.584+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:51:52.641+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:51:52.640+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:51:52.679+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:51:52.678+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:51:52.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.279 seconds
[2025-04-02T00:52:23.030+0000] {processor.py:186} INFO - Started process (PID=13556) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:52:23.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:52:23.050+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:52:23.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:52:25.579+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:52:25.656+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:52:25.654+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:52:25.699+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:52:25.699+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:52:25.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.740 seconds
[2025-04-02T00:52:56.007+0000] {processor.py:186} INFO - Started process (PID=13575) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:52:56.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:52:56.025+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:52:56.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:52:58.113+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:52:58.214+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:52:58.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:52:58.322+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:52:58.322+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:52:58.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.365 seconds
[2025-04-02T00:53:28.831+0000] {processor.py:186} INFO - Started process (PID=13593) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:53:28.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:53:28.853+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:53:28.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:53:30.839+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:53:30.883+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:53:30.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:53:30.921+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:53:30.921+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:53:30.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.132 seconds
[2025-04-02T00:54:01.225+0000] {processor.py:186} INFO - Started process (PID=13612) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:54:01.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:54:01.243+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:54:01.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:54:03.458+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:54:03.512+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:54:03.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:54:03.553+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:54:03.552+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:54:03.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.391 seconds
[2025-04-02T00:54:34.126+0000] {processor.py:186} INFO - Started process (PID=13632) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:54:34.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:54:34.154+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:54:34.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:54:37.757+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:54:37.799+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:54:37.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:54:37.839+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:54:37.839+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:54:37.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.796 seconds
[2025-04-02T00:55:08.503+0000] {processor.py:186} INFO - Started process (PID=13650) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:55:08.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:55:08.517+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:55:08.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:55:12.025+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:55:12.170+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:55:12.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:55:12.242+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:55:12.239+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:55:12.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.801 seconds
[2025-04-02T00:55:42.465+0000] {processor.py:186} INFO - Started process (PID=13669) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:55:42.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:55:42.487+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:55:42.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:55:45.429+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:55:45.523+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:55:45.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:55:45.587+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:55:45.587+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:55:45.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.194 seconds
[2025-04-02T00:56:15.776+0000] {processor.py:186} INFO - Started process (PID=13688) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:56:15.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:56:15.787+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:56:15.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:56:18.006+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:56:18.050+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:56:18.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:56:18.093+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:56:18.093+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:56:18.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.373 seconds
[2025-04-02T00:56:48.664+0000] {processor.py:186} INFO - Started process (PID=13706) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:56:48.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:56:48.683+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:56:48.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:56:50.894+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:56:50.936+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:56:50.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:56:50.982+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:56:50.982+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:56:51.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.373 seconds
[2025-04-02T00:57:21.364+0000] {processor.py:186} INFO - Started process (PID=13725) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:57:21.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:57:21.377+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:57:21.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:57:23.836+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:57:23.881+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:57:23.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:57:23.926+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:57:23.926+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:57:23.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.630 seconds
[2025-04-02T00:57:54.560+0000] {processor.py:186} INFO - Started process (PID=13750) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:57:54.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:57:54.576+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:57:54.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:57:56.790+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:57:56.847+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:57:56.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:57:56.888+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:57:56.887+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:57:56.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.388 seconds
[2025-04-02T00:58:27.493+0000] {processor.py:186} INFO - Started process (PID=13769) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:58:27.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:58:27.499+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:58:27.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:58:29.831+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:58:29.909+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:58:29.908+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:58:29.968+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:58:29.968+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:58:30.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.536 seconds
[2025-04-02T00:59:00.468+0000] {processor.py:186} INFO - Started process (PID=13790) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:59:00.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:59:00.479+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:59:00.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:59:02.739+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:59:02.831+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:59:02.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:59:02.893+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:59:02.892+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:59:02.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.506 seconds
[2025-04-02T00:59:33.146+0000] {processor.py:186} INFO - Started process (PID=13809) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:59:33.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T00:59:33.155+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:59:33.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:59:36.800+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T00:59:36.898+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:59:36.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T00:59:36.984+0000] {logging_mixin.py:190} INFO - [2025-04-02T00:59:36.984+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T00:59:37.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.907 seconds
[2025-04-02T01:00:07.578+0000] {processor.py:186} INFO - Started process (PID=13825) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:00:07.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:00:07.587+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:00:07.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:00:11.229+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:00:11.385+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:00:11.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:00:11.502+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:00:11.501+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:00:11.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.008 seconds
[2025-04-02T01:00:41.955+0000] {processor.py:186} INFO - Started process (PID=13848) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:00:41.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:00:41.961+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:00:41.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:00:44.216+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:00:44.282+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:00:44.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:00:44.342+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:00:44.342+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:00:44.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.455 seconds
[2025-04-02T01:01:15.273+0000] {processor.py:186} INFO - Started process (PID=13868) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:01:15.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:01:15.277+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:01:15.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:01:17.643+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:01:17.683+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:01:17.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:01:17.718+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:01:17.718+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:01:17.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.499 seconds
[2025-04-02T01:01:48.775+0000] {processor.py:186} INFO - Started process (PID=13889) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:01:48.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:01:48.780+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:01:48.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:01:50.838+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:01:50.876+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:01:50.875+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:01:50.913+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:01:50.913+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:01:50.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.183 seconds
[2025-04-02T01:02:21.604+0000] {processor.py:186} INFO - Started process (PID=13907) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:02:21.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:02:21.609+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:02:21.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:02:23.643+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:02:23.706+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:02:23.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:02:23.748+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:02:23.747+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:02:23.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.192 seconds
[2025-04-02T01:02:54.186+0000] {processor.py:186} INFO - Started process (PID=13932) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:02:54.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:02:54.200+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:02:54.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:02:58.768+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:02:58.813+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:02:58.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:02:58.856+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:02:58.856+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:02:58.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.806 seconds
[2025-04-02T01:03:29.779+0000] {processor.py:186} INFO - Started process (PID=13950) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:03:29.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:03:29.786+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:03:29.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:03:32.441+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:03:32.493+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:03:32.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:03:32.544+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:03:32.543+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:03:32.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.824 seconds
[2025-04-02T01:04:03.008+0000] {processor.py:186} INFO - Started process (PID=13969) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:04:03.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:04:03.019+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:04:03.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:04:05.066+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:04:05.116+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:04:05.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:04:05.150+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:04:05.149+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:04:05.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.208 seconds
[2025-04-02T01:04:35.549+0000] {processor.py:186} INFO - Started process (PID=13988) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:04:35.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:04:35.559+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:04:35.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:04:37.661+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:04:37.712+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:04:37.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:04:37.750+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:04:37.750+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:04:37.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.280 seconds
[2025-04-02T01:05:08.077+0000] {processor.py:186} INFO - Started process (PID=14007) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:05:08.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:05:08.085+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:05:08.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:05:10.243+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:05:10.292+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:05:10.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:05:10.330+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:05:10.329+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:05:10.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.319 seconds
[2025-04-02T01:05:40.882+0000] {processor.py:186} INFO - Started process (PID=14025) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:05:40.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:05:40.889+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:05:40.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:05:43.312+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:05:43.355+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:05:43.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:05:43.394+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:05:43.394+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:05:43.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.568 seconds
[2025-04-02T01:06:13.543+0000] {processor.py:186} INFO - Started process (PID=14042) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:06:13.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:06:13.550+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:06:13.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:06:16.925+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:06:17.019+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:06:17.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:06:17.090+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:06:17.090+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:06:17.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.609 seconds
[2025-04-02T01:06:47.547+0000] {processor.py:186} INFO - Started process (PID=14059) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:06:47.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:06:47.553+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:06:47.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:06:50.564+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:06:50.668+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:06:50.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:06:50.757+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:06:50.757+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:06:50.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.324 seconds
[2025-04-02T01:07:21.913+0000] {processor.py:186} INFO - Started process (PID=14078) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:07:21.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:07:21.920+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:07:21.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:07:24.392+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:07:24.456+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:07:24.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:07:24.503+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:07:24.502+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:07:24.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.657 seconds
[2025-04-02T01:07:55.269+0000] {processor.py:186} INFO - Started process (PID=14097) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:07:55.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:07:55.274+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:07:55.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:07:57.757+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:07:57.805+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:07:57.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:07:57.849+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:07:57.849+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:07:57.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.628 seconds
[2025-04-02T01:08:28.449+0000] {processor.py:186} INFO - Started process (PID=14123) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:08:28.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:08:28.456+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:08:28.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:08:30.656+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:08:30.714+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:08:30.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:08:30.761+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:08:30.761+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:08:30.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.383 seconds
[2025-04-02T01:09:01.053+0000] {processor.py:186} INFO - Started process (PID=14142) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:09:01.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:09:01.058+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:09:01.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:09:03.604+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:09:03.668+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:09:03.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:09:03.729+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:09:03.728+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:09:03.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.722 seconds
[2025-04-02T01:09:33.979+0000] {processor.py:186} INFO - Started process (PID=14160) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:09:33.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:09:33.985+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:09:33.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:09:36.194+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:09:36.289+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:09:36.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:09:36.360+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:09:36.359+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:09:36.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.439 seconds
[2025-04-02T01:10:06.843+0000] {processor.py:186} INFO - Started process (PID=14180) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:10:06.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:10:06.851+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:10:06.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:10:09.312+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:10:09.357+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:10:09.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:10:09.398+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:10:09.398+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:10:09.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.624 seconds
[2025-04-02T01:10:39.972+0000] {processor.py:186} INFO - Started process (PID=14199) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:10:39.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:10:39.987+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:10:39.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:10:42.406+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:10:42.454+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:10:42.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:10:42.492+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:10:42.491+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:10:42.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.592 seconds
[2025-04-02T01:11:12.837+0000] {processor.py:186} INFO - Started process (PID=14218) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:11:12.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:11:12.852+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:11:12.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:11:15.139+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:11:15.205+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:11:15.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:11:15.252+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:11:15.251+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:11:15.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.460 seconds
[2025-04-02T01:11:45.890+0000] {processor.py:186} INFO - Started process (PID=14236) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:11:45.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:11:45.944+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:11:45.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:11:51.332+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:11:51.391+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:11:51.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:11:51.427+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:11:51.427+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:11:51.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 5.763 seconds
[2025-04-02T01:12:22.382+0000] {processor.py:186} INFO - Started process (PID=14255) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:12:22.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:12:22.463+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:12:22.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:12:34.674+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:12:34.931+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:12:34.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:12:34.980+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:12:34.980+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:12:35.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 12.858 seconds
[2025-04-02T01:13:05.971+0000] {processor.py:186} INFO - Started process (PID=14280) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:13:05.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:13:06.001+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:13:06.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:13:10.330+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:13:10.400+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:13:10.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:13:10.445+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:13:10.444+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:13:10.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.519 seconds
[2025-04-02T01:13:41.987+0000] {processor.py:186} INFO - Started process (PID=14307) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:13:42.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:13:42.005+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:13:42.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:13:45.778+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:13:45.825+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:13:45.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:13:45.892+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:13:45.892+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:13:45.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.948 seconds
[2025-04-02T01:14:16.675+0000] {processor.py:186} INFO - Started process (PID=14326) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:14:16.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:14:16.695+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:14:16.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:14:19.836+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:14:19.884+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:14:19.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:14:19.978+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:14:19.977+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:14:20.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.420 seconds
[2025-04-02T01:14:50.503+0000] {processor.py:186} INFO - Started process (PID=14345) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:14:50.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:14:50.531+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:14:50.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:14:53.059+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:14:53.118+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:14:53.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:14:53.175+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:14:53.175+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:14:53.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.738 seconds
[2025-04-02T01:21:28.092+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:21:28.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:21:28.107+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:28.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:21:38.429+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:21:40.474+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.473+0000] {override.py:1901} INFO - Created Permission View: can edit on DAG:4-Procesa_data
[2025-04-02T01:21:40.534+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.534+0000] {override.py:1901} INFO - Created Permission View: can read on DAG:4-Procesa_data
[2025-04-02T01:21:40.570+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.568+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG:4-Procesa_data
[2025-04-02T01:21:40.614+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.611+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG Run:4-Procesa_data
[2025-04-02T01:21:40.664+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.661+0000] {override.py:1901} INFO - Created Permission View: can read on DAG Run:4-Procesa_data
[2025-04-02T01:21:40.695+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.694+0000] {override.py:1901} INFO - Created Permission View: can create on DAG Run:4-Procesa_data
[2025-04-02T01:21:40.740+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.739+0000] {override.py:1901} INFO - Created Permission View: menu access on DAG Run:4-Procesa_data
[2025-04-02T01:21:40.743+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:21:40.844+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.835+0000] {dag.py:3262} INFO - Creating ORM DAG for 4-Procesa_data
[2025-04-02T01:21:40.921+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:21:40.921+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:21:40.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 12.903 seconds
[2025-04-02T01:22:11.447+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:22:11.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:22:11.459+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:22:11.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:22:17.242+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:22:17.440+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:22:17.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:22:17.629+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:22:17.628+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:22:18.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 7.194 seconds
[2025-04-02T01:22:49.689+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:22:49.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:22:49.698+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:22:49.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:22:52.322+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:22:52.369+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:22:52.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:22:52.412+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:22:52.412+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:22:52.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.766 seconds
[2025-04-02T01:23:23.153+0000] {processor.py:186} INFO - Started process (PID=142) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:23:23.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:23:23.179+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:23:23.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:23:25.601+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:23:25.670+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:23:25.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:23:25.727+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:23:25.727+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:23:25.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.667 seconds
[2025-04-02T01:23:56.351+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:23:56.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:23:56.370+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:23:56.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:23:59.151+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:23:59.246+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:23:59.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:23:59.293+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:23:59.292+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:23:59.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.223 seconds
[2025-04-02T01:24:30.166+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:24:30.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:24:30.176+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:24:30.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:24:32.871+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:24:32.934+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:24:32.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:24:33.193+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:24:33.193+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:24:33.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.082 seconds
[2025-04-02T01:25:04.432+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:25:04.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:25:04.439+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:25:04.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:25:06.429+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:25:06.513+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:25:06.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:25:06.566+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:25:06.565+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:25:06.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.181 seconds
[2025-04-02T01:25:37.347+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:25:37.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:25:37.356+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:25:37.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:25:39.578+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:25:39.666+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:25:39.662+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:25:39.726+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:25:39.726+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:25:39.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.638 seconds
[2025-04-02T01:26:10.198+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:26:10.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:26:10.215+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:26:10.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:26:13.343+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:26:13.395+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:26:13.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:26:13.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.511 seconds
[2025-04-02T01:26:44.233+0000] {processor.py:186} INFO - Started process (PID=263) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:26:44.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:26:44.243+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:26:44.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:26:47.024+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:26:47.072+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:26:47.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:26:47.117+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:26:47.117+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:26:47.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.937 seconds
[2025-04-02T01:27:17.551+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:27:17.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:27:17.572+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:27:17.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:27:19.915+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:27:19.958+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:27:19.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:27:19.994+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:27:19.994+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:27:20.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.706 seconds
[2025-04-02T01:27:50.528+0000] {processor.py:186} INFO - Started process (PID=298) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:27:50.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:27:50.555+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:27:50.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:27:53.904+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:27:53.949+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:27:53.948+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:27:54.165+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:27:54.164+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:27:54.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.701 seconds
[2025-04-02T01:28:24.732+0000] {processor.py:186} INFO - Started process (PID=323) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:28:24.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:28:24.757+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:28:24.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:28:28.880+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:28:28.941+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:28:28.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:28:28.980+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:28:28.980+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:28:29.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.313 seconds
[2025-04-02T01:28:59.435+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:28:59.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:28:59.446+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:28:59.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:29:01.971+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:29:02.018+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:29:02.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:29:02.068+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:29:02.068+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:29:02.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.921 seconds
[2025-04-02T01:32:13.225+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:32:13.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:32:13.251+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:13.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:32:27.471+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:32:27.996+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:27.995+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG:4-Procesa_data
[2025-04-02T01:32:28.008+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:28.008+0000] {override.py:1901} INFO - Created Permission View: can edit on DAG:4-Procesa_data
[2025-04-02T01:32:28.017+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:28.016+0000] {override.py:1901} INFO - Created Permission View: can read on DAG:4-Procesa_data
[2025-04-02T01:32:28.026+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:28.026+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG Run:4-Procesa_data
[2025-04-02T01:32:28.035+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:28.035+0000] {override.py:1901} INFO - Created Permission View: menu access on DAG Run:4-Procesa_data
[2025-04-02T01:32:28.043+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:28.043+0000] {override.py:1901} INFO - Created Permission View: can create on DAG Run:4-Procesa_data
[2025-04-02T01:32:28.052+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:28.052+0000] {override.py:1901} INFO - Created Permission View: can read on DAG Run:4-Procesa_data
[2025-04-02T01:32:28.053+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:28.053+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:32:28.072+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:28.071+0000] {dag.py:3262} INFO - Creating ORM DAG for 4-Procesa_data
[2025-04-02T01:32:28.089+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:32:28.089+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:32:28.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 14.922 seconds
[2025-04-02T01:39:18.689+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:39:18.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:39:18.713+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:18.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:39:27.330+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:39:28.156+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.155+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG:4-Procesa_data
[2025-04-02T01:39:28.179+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.178+0000] {override.py:1901} INFO - Created Permission View: can read on DAG:4-Procesa_data
[2025-04-02T01:39:28.192+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.192+0000] {override.py:1901} INFO - Created Permission View: can edit on DAG:4-Procesa_data
[2025-04-02T01:39:28.214+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.213+0000] {override.py:1901} INFO - Created Permission View: can create on DAG Run:4-Procesa_data
[2025-04-02T01:39:28.229+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.229+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG Run:4-Procesa_data
[2025-04-02T01:39:28.244+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.243+0000] {override.py:1901} INFO - Created Permission View: menu access on DAG Run:4-Procesa_data
[2025-04-02T01:39:28.258+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.257+0000] {override.py:1901} INFO - Created Permission View: can read on DAG Run:4-Procesa_data
[2025-04-02T01:39:28.259+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:39:28.308+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.306+0000] {dag.py:3262} INFO - Creating ORM DAG for 4-Procesa_data
[2025-04-02T01:39:28.329+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:28.328+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:39:28.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 10.000 seconds
[2025-04-02T01:39:58.966+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:39:58.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:39:58.974+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:39:58.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:40:04.391+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:40:04.456+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:40:04.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:40:04.490+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:40:04.490+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:40:04.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 5.860 seconds
[2025-04-02T01:40:35.330+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:40:35.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:40:35.340+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:40:35.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:40:39.164+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:40:39.206+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:40:39.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:40:39.243+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:40:39.242+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:40:39.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.963 seconds
[2025-04-02T01:41:09.754+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:41:09.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:41:09.766+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:41:09.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:41:12.646+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:41:12.699+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:41:12.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:41:12.740+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:41:12.740+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:41:12.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.047 seconds
[2025-04-02T01:41:43.693+0000] {processor.py:186} INFO - Started process (PID=154) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:41:43.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:41:43.701+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:41:43.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:41:49.388+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:41:49.437+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:41:49.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:41:49.489+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:41:49.488+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:41:49.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 6.162 seconds
[2025-04-02T01:42:20.617+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:42:20.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:42:20.674+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:42:20.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:42:24.477+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:42:24.602+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:42:24.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:42:25.403+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:42:25.402+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:42:25.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.885 seconds
[2025-04-02T01:42:55.723+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:42:55.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:42:55.730+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:42:55.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:42:57.960+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:42:58.023+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:42:58.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:42:58.081+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:42:58.080+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:42:58.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.406 seconds
[2025-04-02T01:43:28.939+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:43:28.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:43:28.948+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:43:28.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:43:31.250+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:43:31.290+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:43:31.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:43:31.325+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:43:31.324+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:43:31.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.431 seconds
[2025-04-02T01:44:02.261+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:44:02.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:44:02.270+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:44:02.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:44:04.242+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:44:04.294+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:44:04.293+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:44:04.504+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:44:04.504+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:00:00+00:00, run_after=2025-04-02 00:00:00+00:00
[2025-04-02T01:44:04.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.296 seconds
[2025-04-02T01:44:36.493+0000] {processor.py:186} INFO - Started process (PID=262) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:44:36.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:44:36.518+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:44:36.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:44:39.008+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:44:39.102+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:44:39.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:44:39.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.790 seconds
[2025-04-02T01:45:10.271+0000] {processor.py:186} INFO - Started process (PID=281) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:45:10.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:45:10.281+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:45:10.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:45:12.490+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:45:12.537+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:45:12.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:45:12.580+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:45:12.579+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:45:12.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.524 seconds
[2025-04-02T01:45:42.926+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:45:42.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:45:42.933+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:45:42.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:45:44.742+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:45:44.792+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:45:44.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:45:45.007+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:45:45.007+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:45:45.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.121 seconds
[2025-04-02T01:46:15.149+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:46:15.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:46:15.160+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:46:15.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:46:16.935+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:46:16.973+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:46:16.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:46:17.006+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:46:17.006+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:46:17.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 1.895 seconds
[2025-04-02T01:46:47.316+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:46:47.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:46:47.327+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:46:47.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:46:49.313+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:46:49.355+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:46:49.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:46:49.390+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:46:49.390+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:46:49.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.302 seconds
[2025-04-02T01:47:19.822+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:47:19.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:47:19.832+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:47:19.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:47:21.783+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:47:21.822+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:47:21.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:47:22.036+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:47:22.035+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:47:22.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.257 seconds
[2025-04-02T01:47:52.270+0000] {processor.py:186} INFO - Started process (PID=382) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:47:52.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:47:52.277+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:47:52.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:47:54.185+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:47:54.229+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:47:54.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:47:54.264+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:47:54.263+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:47:54.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.036 seconds
[2025-04-02T01:48:24.607+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:48:24.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:48:24.613+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:48:24.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:48:26.352+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:48:26.398+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:48:26.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:48:26.445+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:48:26.445+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:48:26.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.053 seconds
[2025-04-02T01:48:56.950+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:48:56.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:48:56.963+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:48:56.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:48:59.039+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:48:59.077+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:48:59.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:48:59.286+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:48:59.285+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:48:59.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.385 seconds
[2025-04-02T01:49:29.620+0000] {processor.py:186} INFO - Started process (PID=438) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:49:29.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:49:29.635+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:49:29.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:49:31.605+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:49:31.655+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:49:31.654+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:49:31.695+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:49:31.695+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:49:31.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.120 seconds
[2025-04-02T01:50:01.902+0000] {processor.py:186} INFO - Started process (PID=457) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:50:01.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:50:01.909+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:50:01.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:50:03.701+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:50:03.757+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:50:03.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:50:03.799+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:50:03.799+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:50:04.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.122 seconds
[2025-04-02T01:50:34.160+0000] {processor.py:186} INFO - Started process (PID=477) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:50:34.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:50:34.169+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:50:34.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:50:35.943+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:50:35.990+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:50:35.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:50:36.194+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:50:36.194+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:50:36.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.073 seconds
[2025-04-02T01:51:06.515+0000] {processor.py:186} INFO - Started process (PID=497) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:51:06.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:51:06.523+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:51:06.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:51:08.254+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:51:08.467+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:51:08.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:51:08.501+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:51:08.500+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:51:08.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.028 seconds
[2025-04-02T01:51:38.884+0000] {processor.py:186} INFO - Started process (PID=516) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:51:38.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:51:38.891+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:51:38.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:51:40.799+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:51:40.836+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:51:40.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:51:40.869+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:51:40.869+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:51:40.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.022 seconds
[2025-04-02T01:52:11.297+0000] {processor.py:186} INFO - Started process (PID=535) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:52:11.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:52:11.304+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:52:11.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:52:13.096+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:52:13.136+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:52:13.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:52:13.370+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:52:13.370+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:52:13.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.114 seconds
[2025-04-02T01:52:43.791+0000] {processor.py:186} INFO - Started process (PID=554) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:52:43.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:52:43.800+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:52:43.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:52:45.635+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:52:45.682+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:52:45.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:52:45.902+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:52:45.901+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:52:45.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.169 seconds
[2025-04-02T01:53:16.241+0000] {processor.py:186} INFO - Started process (PID=573) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:53:16.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:53:16.260+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:53:16.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:53:19.079+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:53:19.122+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:53:19.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:53:19.159+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:53:19.158+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:53:19.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.994 seconds
[2025-04-02T01:53:49.708+0000] {processor.py:186} INFO - Started process (PID=598) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:53:49.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:53:49.726+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:53:49.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:53:51.800+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:53:51.849+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:53:51.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:53:52.072+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:53:52.072+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:53:52.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.418 seconds
[2025-04-02T01:54:22.527+0000] {processor.py:186} INFO - Started process (PID=617) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:54:22.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:54:22.536+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:54:22.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:54:24.394+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:54:24.455+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:54:24.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:54:24.680+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:54:24.679+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:54:24.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.195 seconds
[2025-04-02T01:54:55.175+0000] {processor.py:186} INFO - Started process (PID=637) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:54:55.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:54:55.184+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:54:55.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:54:57.429+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:54:57.494+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:54:57.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:54:57.552+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:54:57.551+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:54:57.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.430 seconds
[2025-04-02T01:55:27.997+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:55:28.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:55:28.010+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:55:28.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:55:30.731+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:55:30.774+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:55:30.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:55:30.812+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:55:30.812+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:55:31.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.107 seconds
[2025-04-02T01:56:01.662+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:56:01.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:56:01.670+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:56:01.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:56:03.563+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:56:03.607+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:56:03.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:56:03.840+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:56:03.839+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:56:03.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.230 seconds
[2025-04-02T01:56:34.422+0000] {processor.py:186} INFO - Started process (PID=694) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:56:34.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:56:34.439+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:56:34.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:56:36.727+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:56:36.955+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:56:36.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:56:36.993+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:56:36.993+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:56:37.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.640 seconds
[2025-04-02T01:57:07.713+0000] {processor.py:186} INFO - Started process (PID=712) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:57:07.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:57:07.735+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:57:07.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:57:09.980+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:57:10.026+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:57:10.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:57:10.065+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:57:10.065+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:57:10.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.417 seconds
[2025-04-02T01:57:40.989+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:57:40.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:57:40.996+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:57:40.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:57:42.973+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:57:43.015+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:57:43.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:57:43.227+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:57:43.227+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:57:43.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.281 seconds
[2025-04-02T01:58:13.529+0000] {processor.py:186} INFO - Started process (PID=750) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:58:13.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:58:13.537+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:58:13.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:58:15.964+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:58:16.211+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:58:16.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:58:16.248+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:58:16.247+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:58:16.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.761 seconds
[2025-04-02T01:58:46.681+0000] {processor.py:186} INFO - Started process (PID=771) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:58:46.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:58:46.688+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:58:46.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:58:48.930+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:58:48.985+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:58:48.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:58:49.040+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:58:49.039+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:58:49.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.403 seconds
[2025-04-02T01:59:19.428+0000] {processor.py:186} INFO - Started process (PID=791) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:59:19.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:59:19.435+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:59:19.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:59:21.333+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:59:21.375+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:59:21.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:59:21.590+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:59:21.590+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:59:21.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.206 seconds
[2025-04-02T01:59:51.842+0000] {processor.py:186} INFO - Started process (PID=816) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:59:51.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T01:59:51.850+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:59:51.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:59:53.732+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T01:59:53.946+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:59:53.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T01:59:53.981+0000] {logging_mixin.py:190} INFO - [2025-04-02T01:59:53.980+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T01:59:54.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.176 seconds
[2025-04-02T02:00:24.207+0000] {processor.py:186} INFO - Started process (PID=835) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:00:24.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:00:24.214+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:00:24.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:00:26.698+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:00:26.752+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:00:26.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:00:26.800+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:00:26.800+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:00:26.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.639 seconds
[2025-04-02T02:00:56.991+0000] {processor.py:186} INFO - Started process (PID=854) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:00:56.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:00:56.999+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:00:56.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:00:59.168+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:00:59.213+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:00:59.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:00:59.257+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:00:59.257+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:00:59.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.306 seconds
[2025-04-02T02:01:30.371+0000] {processor.py:186} INFO - Started process (PID=875) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:01:30.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:01:30.378+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:01:30.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:01:32.375+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:01:32.424+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:01:32.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:01:32.466+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:01:32.466+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:01:32.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.148 seconds
[2025-04-02T02:02:03.082+0000] {processor.py:186} INFO - Started process (PID=893) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:02:03.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:02:03.089+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:02:03.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:02:05.164+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:02:05.206+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:02:05.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:02:05.241+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:02:05.241+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:02:05.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.202 seconds
[2025-04-02T02:02:35.512+0000] {processor.py:186} INFO - Started process (PID=912) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:02:35.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:02:35.519+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:02:35.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:02:37.523+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:02:37.564+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:02:37.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:02:37.600+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:02:37.599+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:02:37.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.129 seconds
[2025-04-02T02:03:07.999+0000] {processor.py:186} INFO - Started process (PID=931) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:03:08.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:03:08.007+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:03:08.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:03:10.064+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:03:10.115+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:03:10.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:03:10.155+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:03:10.154+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:03:10.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.201 seconds
[2025-04-02T02:03:40.350+0000] {processor.py:186} INFO - Started process (PID=950) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:03:40.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:03:40.356+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:03:40.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:03:42.378+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:03:42.425+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:03:42.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:03:42.459+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:03:42.458+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:03:42.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.150 seconds
[2025-04-02T02:04:13.013+0000] {processor.py:186} INFO - Started process (PID=969) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:04:13.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:04:13.021+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:04:13.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:04:15.013+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:04:15.054+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:04:15.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:04:15.094+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:04:15.093+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:04:15.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.124 seconds
[2025-04-02T02:04:45.557+0000] {processor.py:186} INFO - Started process (PID=988) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:04:45.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:04:45.564+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:04:45.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:04:48.271+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:04:48.314+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:04:48.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:04:48.349+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:04:48.348+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:04:48.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.833 seconds
[2025-04-02T02:05:18.780+0000] {processor.py:186} INFO - Started process (PID=1007) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:05:18.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:05:18.788+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:05:18.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:05:20.777+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:05:20.821+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:05:20.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:05:20.854+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:05:20.853+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:05:20.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.111 seconds
[2025-04-02T02:05:51.312+0000] {processor.py:186} INFO - Started process (PID=1026) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:05:51.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:05:51.320+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:05:51.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:05:53.369+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:05:53.413+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:05:53.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:05:53.453+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:05:53.453+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:05:53.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.195 seconds
[2025-04-02T02:06:23.954+0000] {processor.py:186} INFO - Started process (PID=1056) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:06:23.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:06:23.974+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:06:23.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:06:28.059+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:06:28.125+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:06:28.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:06:28.167+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:06:28.167+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:06:28.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.291 seconds
[2025-04-02T02:06:58.531+0000] {processor.py:186} INFO - Started process (PID=1076) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:06:58.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:06:58.540+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:06:58.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:07:01.633+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:07:01.689+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:07:01.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:07:01.732+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:07:01.732+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:07:01.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.280 seconds
[2025-04-02T02:07:32.472+0000] {processor.py:186} INFO - Started process (PID=1095) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:07:32.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:07:32.479+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:07:32.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:07:34.577+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:07:34.645+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:07:34.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:07:34.707+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:07:34.706+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:07:34.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.296 seconds
[2025-04-02T02:08:05.186+0000] {processor.py:186} INFO - Started process (PID=1115) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:08:05.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:08:05.194+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:08:05.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:08:07.181+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:08:07.219+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:08:07.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:08:07.256+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:08:07.255+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:08:07.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.110 seconds
[2025-04-02T02:08:37.806+0000] {processor.py:186} INFO - Started process (PID=1134) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:08:37.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:08:37.814+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:08:37.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:08:40.163+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:08:40.275+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:08:40.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:08:40.317+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:08:40.316+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:08:40.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.553 seconds
[2025-04-02T02:09:10.750+0000] {processor.py:186} INFO - Started process (PID=1152) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:09:10.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:09:10.756+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:09:10.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:09:12.769+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:09:12.809+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:09:12.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:09:12.844+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:09:12.843+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:09:12.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.133 seconds
[2025-04-02T02:09:43.001+0000] {processor.py:186} INFO - Started process (PID=1172) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:09:43.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:09:43.010+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:09:43.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:09:45.064+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:09:45.102+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:09:45.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:09:45.139+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:09:45.138+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:00:00+00:00, run_after=2025-04-03 00:00:00+00:00
[2025-04-02T02:09:45.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.182 seconds
[2025-04-02T02:10:13.364+0000] {processor.py:186} INFO - Started process (PID=1190) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:10:13.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:10:13.373+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:10:13.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:10:15.470+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:10:15.649+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:10:15.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:10:15.681+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:10:15.681+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 01:10:00+00:00, run_after=2025-04-02 02:10:00+00:00
[2025-04-02T02:10:15.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.364 seconds
[2025-04-02T02:10:46.381+0000] {processor.py:186} INFO - Started process (PID=1211) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:10:46.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:10:46.388+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:10:46.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:10:48.471+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:10:48.521+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:10:48.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:10:48.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.213 seconds
[2025-04-02T02:11:18.997+0000] {processor.py:186} INFO - Started process (PID=1230) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:11:19.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:11:19.005+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:11:19.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:11:21.117+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:11:21.157+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:11:21.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:11:21.192+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:11:21.192+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:11:21.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.242 seconds
[2025-04-02T02:11:51.831+0000] {processor.py:186} INFO - Started process (PID=1249) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:11:51.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:11:51.846+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:11:51.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:11:54.486+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:11:54.529+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:11:54.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:11:54.566+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:11:54.566+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:11:54.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.788 seconds
[2025-04-02T02:12:25.097+0000] {processor.py:186} INFO - Started process (PID=1274) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:12:25.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:12:25.106+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:12:25.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:12:27.762+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:12:27.818+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:12:27.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:12:27.858+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:12:27.857+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:12:27.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.808 seconds
[2025-04-02T02:12:58.439+0000] {processor.py:186} INFO - Started process (PID=1292) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:12:58.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:12:58.450+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:12:58.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:13:00.978+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:13:01.018+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:13:01.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:13:01.056+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:13:01.055+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:13:01.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.665 seconds
[2025-04-02T02:13:31.247+0000] {processor.py:186} INFO - Started process (PID=1312) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:13:31.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:13:31.255+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:13:31.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:13:33.254+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:13:33.303+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:13:33.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:13:33.340+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:13:33.339+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:13:33.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.135 seconds
[2025-04-02T02:14:03.790+0000] {processor.py:186} INFO - Started process (PID=1330) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:14:03.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:14:03.802+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:14:03.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:14:05.833+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:14:05.872+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:14:05.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:14:05.909+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:14:05.908+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:14:05.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.169 seconds
[2025-04-02T02:14:36.400+0000] {processor.py:186} INFO - Started process (PID=1349) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:14:36.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:14:36.408+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:14:36.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:14:38.435+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:14:38.478+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:14:38.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:14:38.518+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:14:38.518+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:14:38.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.166 seconds
[2025-04-02T02:15:08.945+0000] {processor.py:186} INFO - Started process (PID=1368) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:15:08.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:15:08.954+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:15:08.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:15:10.904+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:15:10.944+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:15:10.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:15:10.979+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:15:10.979+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:15:11.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.075 seconds
[2025-04-02T02:15:41.269+0000] {processor.py:186} INFO - Started process (PID=1387) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:15:41.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:15:41.276+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:15:41.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:15:43.268+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:15:43.314+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:15:43.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:15:43.363+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:15:43.363+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:15:43.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.139 seconds
[2025-04-02T02:16:13.936+0000] {processor.py:186} INFO - Started process (PID=1406) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:16:13.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:16:13.944+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:16:13.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:16:15.960+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:16:16.005+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:16:16.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:16:16.042+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:16:16.041+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:16:16.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.152 seconds
[2025-04-02T02:16:46.430+0000] {processor.py:186} INFO - Started process (PID=1425) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:16:46.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:16:46.438+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:16:46.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:16:48.470+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:16:48.509+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:16:48.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:16:48.543+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:16:48.542+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:16:48.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.151 seconds
[2025-04-02T02:17:19.148+0000] {processor.py:186} INFO - Started process (PID=1444) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:17:19.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:17:19.161+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:17:19.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:17:21.159+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:17:21.199+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:17:21.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:17:21.234+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:17:21.234+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:17:21.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.129 seconds
[2025-04-02T02:17:51.835+0000] {processor.py:186} INFO - Started process (PID=1463) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:17:51.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:17:51.842+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:17:51.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:17:53.744+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:17:53.783+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:17:53.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:17:53.825+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:17:53.825+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:17:53.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.032 seconds
[2025-04-02T02:18:24.358+0000] {processor.py:186} INFO - Started process (PID=1487) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:18:24.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:18:24.367+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:18:24.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:18:26.440+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:18:26.483+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:18:26.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:18:26.521+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:18:26.521+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:18:26.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.215 seconds
[2025-04-02T02:18:56.795+0000] {processor.py:186} INFO - Started process (PID=1512) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:18:56.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:18:56.803+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:18:56.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:18:58.945+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:18:58.988+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:18:58.987+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:18:59.024+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:18:59.023+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:18:59.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.275 seconds
[2025-04-02T02:19:29.479+0000] {processor.py:186} INFO - Started process (PID=1531) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:19:29.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:19:29.489+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:19:29.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:19:31.543+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:19:31.583+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:19:31.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:19:31.619+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:19:31.618+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:19:31.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.187 seconds
[2025-04-02T02:20:02.007+0000] {processor.py:186} INFO - Started process (PID=1550) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:20:02.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:20:02.014+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:20:02.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:20:04.066+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:20:04.134+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:20:04.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:20:04.197+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:20:04.196+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:20:04.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.231 seconds
[2025-04-02T02:20:34.824+0000] {processor.py:186} INFO - Started process (PID=1574) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:20:34.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:20:34.833+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:20:34.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:20:36.909+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:20:36.952+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:20:36.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:20:36.986+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:20:36.985+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:20:37.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.199 seconds
[2025-04-02T02:21:07.503+0000] {processor.py:186} INFO - Started process (PID=1593) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:21:07.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:21:07.511+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:21:07.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:21:10.036+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:21:10.077+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:21:10.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:21:10.114+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:21:10.114+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:21:10.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.652 seconds
[2025-04-02T02:21:40.408+0000] {processor.py:186} INFO - Started process (PID=1613) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:21:40.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:21:40.416+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:21:40.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:21:42.415+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:21:42.455+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:21:42.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:21:42.491+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:21:42.491+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:21:42.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.123 seconds
[2025-04-02T02:22:12.936+0000] {processor.py:186} INFO - Started process (PID=1632) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:22:12.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:22:12.947+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:22:12.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:22:15.044+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:22:15.090+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:22:15.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:22:15.125+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:22:15.125+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:22:15.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.229 seconds
[2025-04-02T02:22:45.577+0000] {processor.py:186} INFO - Started process (PID=1650) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:22:45.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:22:45.586+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:22:45.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:22:47.553+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:22:47.596+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:22:47.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:22:47.633+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:22:47.632+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:22:47.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.107 seconds
[2025-04-02T02:23:17.866+0000] {processor.py:186} INFO - Started process (PID=1670) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:23:17.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:23:17.874+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:23:17.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:23:20.752+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:23:20.793+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:23:20.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:23:20.840+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:23:20.839+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 02:10:00+00:00, run_after=2025-04-02 03:10:00+00:00
[2025-04-02T02:23:20.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.024 seconds
[2025-04-02T02:23:27.082+0000] {processor.py:186} INFO - Started process (PID=1676) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:23:27.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:23:27.093+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:23:27.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:23:29.835+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:23:30.036+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:23:30.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:23:30.073+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:23:30.073+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:23:30.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.064 seconds
[2025-04-02T02:24:00.432+0000] {processor.py:186} INFO - Started process (PID=1701) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:24:00.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:24:00.440+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:24:00.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:24:02.704+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:24:02.770+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:24:02.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:24:02.813+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:24:02.812+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:24:02.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.438 seconds
[2025-04-02T02:24:33.669+0000] {processor.py:186} INFO - Started process (PID=1720) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:24:33.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:24:33.677+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:24:33.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:24:35.624+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:24:35.664+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:24:35.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:24:35.697+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:24:35.697+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:24:35.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.070 seconds
[2025-04-02T02:25:06.146+0000] {processor.py:186} INFO - Started process (PID=1740) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:25:06.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:25:06.159+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:25:06.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:25:08.484+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:25:08.545+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:25:08.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:25:08.620+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:25:08.620+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:25:08.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.548 seconds
[2025-04-02T02:25:39.347+0000] {processor.py:186} INFO - Started process (PID=1759) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:25:39.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:25:39.358+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:25:39.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:25:41.309+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:25:41.348+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:25:41.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:25:41.381+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:25:41.380+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:25:41.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.072 seconds
[2025-04-02T02:26:11.591+0000] {processor.py:186} INFO - Started process (PID=1778) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:26:11.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:26:11.598+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:26:11.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:26:13.681+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:26:13.722+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:26:13.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:26:13.776+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:26:13.776+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:26:13.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.236 seconds
[2025-04-02T02:26:44.607+0000] {processor.py:186} INFO - Started process (PID=1797) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:26:44.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:26:44.616+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:26:44.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:26:46.618+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:26:46.657+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:26:46.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:26:46.691+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:26:46.691+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:26:46.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.122 seconds
[2025-04-02T02:27:17.117+0000] {processor.py:186} INFO - Started process (PID=1816) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:27:17.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:27:17.127+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:27:17.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:27:19.801+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:27:19.843+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:27:19.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:27:19.880+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:27:19.880+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:27:19.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.810 seconds
[2025-04-02T02:32:56.796+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:32:56.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:32:56.844+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:32:56.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:33:05.167+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:33:05.791+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.789+0000] {override.py:1901} INFO - Created Permission View: can edit on DAG:4-Procesa_data
[2025-04-02T02:33:05.811+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.810+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG:4-Procesa_data
[2025-04-02T02:33:05.830+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.830+0000] {override.py:1901} INFO - Created Permission View: can read on DAG:4-Procesa_data
[2025-04-02T02:33:05.846+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.845+0000] {override.py:1901} INFO - Created Permission View: can create on DAG Run:4-Procesa_data
[2025-04-02T02:33:05.860+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.859+0000] {override.py:1901} INFO - Created Permission View: can read on DAG Run:4-Procesa_data
[2025-04-02T02:33:05.872+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.871+0000] {override.py:1901} INFO - Created Permission View: menu access on DAG Run:4-Procesa_data
[2025-04-02T02:33:05.896+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.896+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG Run:4-Procesa_data
[2025-04-02T02:33:05.898+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.898+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:33:05.947+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.946+0000] {dag.py:3262} INFO - Creating ORM DAG for 4-Procesa_data
[2025-04-02T02:33:05.977+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:05.977+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:10:00+00:00, run_after=2025-04-02 00:10:00+00:00
[2025-04-02T02:33:06.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 9.310 seconds
[2025-04-02T02:33:36.390+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:33:36.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:33:36.398+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:36.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:33:41.187+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:33:41.258+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:41.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:33:41.323+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:33:41.319+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:10:00+00:00, run_after=2025-04-02 00:10:00+00:00
[2025-04-02T02:33:41.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 5.227 seconds
[2025-04-02T02:34:12.278+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:34:12.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:34:12.285+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:34:12.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:34:15.063+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:34:15.136+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:34:15.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:34:15.209+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:34:15.209+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:10:00+00:00, run_after=2025-04-02 00:10:00+00:00
[2025-04-02T02:34:15.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.012 seconds
[2025-04-02T02:34:46.117+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:34:46.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:34:46.138+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:34:46.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:34:49.987+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:34:50.149+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:34:50.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:34:50.216+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:34:50.211+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-01 00:10:00+00:00, run_after=2025-04-02 00:10:00+00:00
[2025-04-02T02:34:50.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.163 seconds
[2025-04-02T02:35:20.521+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:35:20.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:35:20.530+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:35:20.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:35:24.899+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:35:25.088+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:35:25.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:35:25.268+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:35:25.265+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:35:26.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 5.814 seconds
[2025-04-02T02:35:56.633+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:35:56.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:35:56.642+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:35:56.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:36:00.714+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:36:00.768+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:36:00.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:36:01.037+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:36:01.036+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:36:01.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.489 seconds
[2025-04-02T02:36:31.695+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:36:31.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:36:31.717+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:36:31.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:36:37.450+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:36:37.592+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:36:37.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:36:37.682+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:36:37.682+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:36:37.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 6.096 seconds
[2025-04-02T02:37:07.947+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:37:07.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:37:07.955+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:37:07.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:37:10.733+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:37:10.802+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:37:10.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:37:10.865+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:37:10.863+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:37:10.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.013 seconds
[2025-04-02T02:37:41.670+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:37:41.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:37:41.677+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:37:41.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:37:43.619+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:37:43.661+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:37:43.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:37:43.702+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:37:43.702+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:37:43.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.260 seconds
[2025-04-02T02:38:14.507+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:38:14.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:38:14.514+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:38:14.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:38:16.488+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:38:16.537+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:38:16.535+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:38:16.601+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:38:16.601+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:38:16.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.172 seconds
[2025-04-02T02:38:47.212+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:38:47.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:38:47.220+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:38:47.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:38:49.547+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:38:49.614+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:38:49.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:38:49.652+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:38:49.652+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:38:49.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.480 seconds
[2025-04-02T02:39:19.936+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:39:19.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:39:19.950+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:39:19.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:39:23.091+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:39:23.166+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:39:23.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:39:23.274+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:39:23.273+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:39:23.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.752 seconds
[2025-04-02T02:39:54.304+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:39:54.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:39:54.325+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:39:54.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:39:58.595+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:39:58.670+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:39:58.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:39:59.393+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:39:59.392+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:39:59.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 5.202 seconds
[2025-04-02T02:40:30.158+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:40:30.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:40:30.183+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:40:30.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:40:33.419+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:40:33.462+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:40:33.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:40:33.528+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:40:33.528+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:40:33.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.512 seconds
[2025-04-02T02:41:04.237+0000] {processor.py:186} INFO - Started process (PID=370) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:41:04.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:41:04.245+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:41:04.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:41:07.156+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:41:07.208+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:41:07.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:41:07.283+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:41:07.282+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:41:07.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.696 seconds
[2025-04-02T02:41:38.282+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:41:38.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:41:38.300+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:41:38.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:41:40.578+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:41:40.624+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:41:40.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:41:40.850+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:41:40.850+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:41:40.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.617 seconds
[2025-04-02T02:42:11.320+0000] {processor.py:186} INFO - Started process (PID=414) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:42:11.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:42:11.329+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:42:11.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:42:13.278+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:42:13.321+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:42:13.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:42:13.361+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:42:13.360+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:42:13.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.081 seconds
[2025-04-02T02:42:43.845+0000] {processor.py:186} INFO - Started process (PID=433) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:42:43.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:42:43.853+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:42:43.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:42:46.126+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:42:46.173+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:42:46.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:42:46.207+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:42:46.207+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:42:46.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.582 seconds
[2025-04-02T02:43:16.592+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:43:16.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:43:16.600+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:43:16.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:43:18.592+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:43:18.631+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:43:18.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:43:18.874+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:43:18.874+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:43:18.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.329 seconds
[2025-04-02T02:43:49.453+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:43:49.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:43:49.464+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:43:49.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:43:52.130+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:43:52.174+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:43:52.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:43:52.220+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:43:52.219+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:43:52.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.850 seconds
[2025-04-02T02:44:22.803+0000] {processor.py:186} INFO - Started process (PID=487) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:44:22.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:44:22.848+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:44:22.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:44:26.411+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:44:26.457+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:44:26.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:44:26.508+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:44:26.506+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:44:26.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.040 seconds
[2025-04-02T02:44:57.583+0000] {processor.py:186} INFO - Started process (PID=509) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:44:57.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:44:57.606+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:44:57.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:45:00.345+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:45:00.407+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:45:00.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:45:00.677+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:45:00.677+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:45:00.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.157 seconds
[2025-04-02T02:45:31.144+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:45:31.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:45:31.152+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:45:31.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:45:33.383+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:45:33.427+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:45:33.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:45:33.464+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:45:33.464+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:45:33.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.362 seconds
[2025-04-02T02:46:04.151+0000] {processor.py:186} INFO - Started process (PID=550) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:46:04.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:46:04.160+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:46:04.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:46:06.363+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:46:06.408+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:46:06.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:46:06.446+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:46:06.445+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:46:06.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.598 seconds
[2025-04-02T02:46:37.228+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:46:37.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:46:37.237+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:46:37.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:46:39.146+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:46:39.189+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:46:39.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:46:39.403+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:46:39.402+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:46:39.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.215 seconds
[2025-04-02T02:47:10.099+0000] {processor.py:186} INFO - Started process (PID=594) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:47:10.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:47:10.105+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:47:10.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:47:12.129+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:47:12.170+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:47:12.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:47:12.208+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:47:12.208+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:47:12.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.158 seconds
[2025-04-02T02:47:42.716+0000] {processor.py:186} INFO - Started process (PID=613) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:47:42.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:47:42.724+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:47:42.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:47:44.788+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:47:44.827+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:47:44.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:47:44.861+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:47:44.861+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:47:45.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.362 seconds
[2025-04-02T02:48:15.317+0000] {processor.py:186} INFO - Started process (PID=632) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:48:15.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:48:15.325+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:48:15.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:48:17.469+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:48:17.509+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:48:17.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:48:17.722+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:48:17.721+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:48:17.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.442 seconds
[2025-04-02T02:48:48.117+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:48:48.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:48:48.139+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:48:48.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:48:51.874+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:48:51.960+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:48:51.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:48:52.099+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:48:52.091+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:48:52.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 4.147 seconds
[2025-04-02T02:49:22.415+0000] {processor.py:186} INFO - Started process (PID=670) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:49:22.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:49:22.429+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:49:22.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:49:25.458+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:49:25.504+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:49:25.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:49:25.561+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:49:25.561+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:49:25.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.433 seconds
[2025-04-02T02:49:56.199+0000] {processor.py:186} INFO - Started process (PID=689) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:49:56.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:49:56.214+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:49:56.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:49:58.087+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:49:58.127+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:49:58.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:49:58.335+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:49:58.334+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:49:58.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.178 seconds
[2025-04-02T02:50:28.842+0000] {processor.py:186} INFO - Started process (PID=708) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:50:28.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:50:28.859+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:50:28.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:50:31.231+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:50:31.580+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:50:31.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:50:31.616+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:50:31.616+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:50:31.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.837 seconds
[2025-04-02T02:51:02.276+0000] {processor.py:186} INFO - Started process (PID=727) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:51:02.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:51:02.296+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:51:02.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:51:04.230+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:51:04.271+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:51:04.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:51:04.309+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:51:04.309+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:51:04.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.089 seconds
[2025-04-02T02:51:34.842+0000] {processor.py:186} INFO - Started process (PID=746) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:51:34.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:51:34.858+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:51:34.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:51:37.466+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:51:37.509+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:51:37.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:51:37.548+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:51:37.548+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:51:37.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.960 seconds
[2025-04-02T02:52:08.221+0000] {processor.py:186} INFO - Started process (PID=765) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:52:08.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:52:08.232+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:52:08.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:52:11.776+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:52:11.873+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:52:11.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:52:12.140+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:52:12.140+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:52:12.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.965 seconds
[2025-04-02T02:52:42.616+0000] {processor.py:186} INFO - Started process (PID=790) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:52:42.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:52:42.636+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:52:42.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:52:44.808+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:52:44.895+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:52:44.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:52:44.945+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:52:44.944+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:52:44.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.385 seconds
[2025-04-02T02:53:15.406+0000] {processor.py:186} INFO - Started process (PID=810) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:53:15.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:53:15.414+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:53:15.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:53:17.623+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:53:17.664+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:53:17.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:53:17.701+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:53:17.700+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:53:17.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 2.518 seconds
[2025-04-02T02:53:48.561+0000] {processor.py:186} INFO - Started process (PID=829) to work on /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:53:48.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/Procesa_data.py for tasks to queue
[2025-04-02T02:53:48.573+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:53:48.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:53:51.851+0000] {processor.py:925} INFO - DAG(s) '4-Procesa_data' retrieved from /opt/airflow/dags/Procesa_data.py
[2025-04-02T02:53:51.898+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:53:51.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-02T02:53:52.149+0000] {logging_mixin.py:190} INFO - [2025-04-02T02:53:52.149+0000] {dag.py:4180} INFO - Setting next_dagrun for 4-Procesa_data to 2025-04-02 00:10:00+00:00, run_after=2025-04-03 00:10:00+00:00
[2025-04-02T02:53:52.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/Procesa_data.py took 3.640 seconds
