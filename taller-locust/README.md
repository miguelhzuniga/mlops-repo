# ğŸš€ README para el ClÃºster de Airflow con CeleryExecutor, Redis y PostgreSQL

Este repositorio configura un entorno de desarrollo local para ejecutar Apache Airflow con CeleryExecutor, Redis como broker de tareas y PostgreSQL como backend de la base de datos. AdemÃ¡s, el entorno incluye MinIO para almacenamiento de artefactos, MySQL para almacenar metadata de MLFlow, PgAdmin para monitorear la base de datos de airflow y JupyterLab como ambiente de desarrollo.

---

## ğŸ³ Servicios en Docker Compose

El entorno de desarrollo estÃ¡ compuesto por varios contenedores Docker que incluyen Airflow, bases de datos, almacenamiento de artefactos y mÃ¡s. A continuaciÃ³n, se describen los servicios principales:

### 1. **ğŸ”„ Airflow**: ClÃºster con CeleryExecutor

Airflow se ejecuta utilizando CeleryExecutor, y se conecta a Redis para la gestiÃ³n de tareas y PostgreSQL para el almacenamiento de metadatos.

- **ğŸ–¥ï¸ Airflow Webserver**: Accede a la UI de Airflow en `http://localhost:8080`
- **â° Airflow Scheduler**: Controla la ejecuciÃ³n de tareas programadas.
- **ğŸ‘· Airflow Worker**: Ejecuta las tareas programadas por el scheduler.
- **ğŸ”” Airflow Triggerer**: Gestiona trabajos que activan tareas manualmente.

  ![alt text](images/captura_airflow.png)

### 2. **ğŸ“® Redis**: Broker de Celery

Redis se usa como broker para las tareas de Celery. Es necesario para la comunicaciÃ³n entre el `Scheduler` y los `Workers` de Airflow.

### 3. **ğŸ—ƒï¸ PostgreSQL**: Backend de Airflow

PostgreSQL se usa como base de datos para almacenar los metadatos de Airflow. Se conecta con los `Scheduler` y `Workers`.

### 4. **ğŸ“¦ MinIO**: Almacenamiento S3

MinIO emula un almacenamiento tipo S3, utilizado para almacenar los artefactos de MLFlow.

- Accede a la consola web de MinIO en `http://localhost:9001` utilizando las credenciales:
  - Usuario: `admin`
  - ContraseÃ±a: `supersecret`

- Se debe crear el bucket para almacenar los artefactos de MLFLOW en la interfaz grÃ¡fica por medio del botÃ³n "Create bucket" y este debe llamarse mlflows3 para que mlflow pueda reconocerlo y se guarde la informaciÃ³n.

![alt text](images/captura_minio.png)

### 5. **ğŸ“Š MLFlow**: Plataforma de GestiÃ³n de Experimentos

MLFlow se utiliza para el seguimiento de experimentos de Machine Learning. Se conecta a MySQL para almacenar metadatos.

- Accede a la interfaz web de MLFlow en `http://localhost:5000`.

![alt text](images/captura_mlflow.png)

### 6. **ğŸ” PgAdmin**: Interfaz de AdministraciÃ³n de PostgreSQL

PgAdmin proporciona una interfaz grÃ¡fica para gestionar la base de datos de PostgreSQL.

- Accede a la interfaz web de PgAdmin en `http://localhost:5050`.
  - Usuario: `admin@example.com`
  - ContraseÃ±a: `admin`
Se debe registrar la base de datos con:
- hostname: postgres
- user: airflow
- password: airflow

Para esto se da click en "Servers">"Register" y se ingresan los datos anteriores. Luego se da "Save". AparecerÃ¡ la base de datos a la cual si se despliega se podrÃ¡ dar click derecho y poner "Query tools" y luego hacer consultas como por ejemplo "select * from covertype".

De este modo se puede comprobar que los datos que airflow genera con el dag Cargar_datos.py estÃ¡n cargados a la base de datos de Postgresql

![alt text](images/captura_pgadmin.png)

### 7. **ğŸ’¾ MySQL**: Base de Datos de MLFlow

MySQL se usa para almacenar los metadatos de MLFlow. Se conecta con el contenedor de MLFlow.

### 8. **ğŸ§ª JupyterLab**: Entorno de Desarrollo

JupyterLab proporciona un entorno interactivo para desarrollo y pruebas. Puedes acceder a Ã©l en `http://localhost:8888` usando el token `devtoken`.

![alt text](images/captura_jupyter.png)

### 9. **ğŸ”Œ FastAPI (API)**: API de Inferencia

FastAPI proporciona un servidor para exponer endpoints que interactÃºan con otros servicios como Airflow y MLFlow. Accede al servidor en `http://localhost:8000/docs`.

Aqui se puede utilizar el mejor modelo generado tras los experimentos de MLFLOW para realizar inferencia.

* Nota: el modelo debe estar en estado de producciÃ³n en Mlflow y debe llamarse modelo1.

![alt text](images/captura_api.png)

### 10. **ğŸŒ FastAPI (API Server)**: Servidor de API

Esta API simula una URL de internet que provee un batch de datos cada 5 segundos, para un total de 10 batches, los cuales serÃ¡n utilizados para entrenar posteriormente el modelo en airflow y registrar los experimentos y el mejor modelo en mlflow. Los datos se almacenan en la base de datos "airflow" dentro de la tabla "covertype".
`http://localhost:80`.

---

## ğŸ“‹ Uso

Para ejecutar los contenedores y configurar el entorno, sigue estos pasos:

IP MV: 10.43.101.202


1. **ğŸ› ï¸ Construir los contenedores**:

   En el directorio raÃ­z del proyecto, ejecuta:

   ```bash
   docker-compose up -d --build
   ```
    Para ver el estatus de los servicios:
   ```bash
   docker-compose ps
   ```
    Para bajar los servicios:
   ```bash
   docker-compose down
   ```

   Para bajar los servicios limpiando todo:
   ```bash
   docker-compose down --volumes --remove-orphans
   ```

2. **â–¶ï¸ Prender dags programados**:

    En airflow existen 4 dags que se ejecutan diariamente desde el 30 de marzo del 2025:
    1. ğŸ—‘ï¸ **Borrar_datos**: limpia la base de datos si existe. Se ejecuta posterior a la generaciÃ³n del modelo y estÃ¡ programado 1 hora despuÃ©s de el primer dag. 
    2. ğŸ“¥ **Cargar_datos**: trae los datos consolidados de la api server tarda aproximadamente 50 segundos y estÃ¡ programado a las 0 horas.
    3. ğŸ§  **Entrenamiento_mode**: entrena un RandomForest con los datos cargados, el cual estÃ¡ programado 2 minutos despuÃ©s de cargar los datos.
    4. âš™ï¸ **Procesa_data**: genera experimentos para encontrar los mejores hiperparÃ¡metros y por ende el mejor modelo que serÃ¡ utilizado posteriormente por el usuario. Se ejecuta 10 minutos despuÃ©s de cargar los datos.


    * âš ï¸ La ejecuciÃ³n recomendada para efectuar el proceso por completo es ejecutar los dags en el orden en el que estÃ¡n enumerados: primero se limpia la base de datos si existe, se cargan los datos, se entrena el modelo y se genera experimentos.

3. **ğŸ”® Inferencia en API**:
    Tras la ejecuciÃ³n de los dags, el usuario ingresarÃ¡ a `http://localhost:8000/docs/`, donde podrÃ¡ hacer inferencia con el modelo como el siguiente ejemplo:

    1. FastAPI proporciona un servidor para exponer endpoints que interactÃºan con otros servicios como Airflow y MLFlow. Accede al servidor en http://localhost:8000/docs.

Aqui se puede utilizar el mejor modelo generado tras los experimentos de MLFLOW para realizar inferencia.

Nota: el modelo debe estar en estado de producciÃ³n en Mlflow y debe llamarse modelo1.

4. **ğŸ“ˆ Prueba de carga con Locust**

---

## ğŸ”Œ Endpoints de la API

### `POST /select-model`
Selecciona el modelo que se usarÃ¡ para predicciÃ³n.

```json
{
  "model_name": "modelo1"
}
```

### `POST /predict`

Realiza una inferencia con el modelo seleccionado.

```json
{
  "Elevation": 1,
  "Aspect": 1,
  "Slope": 1,
  "Horizontal_Distance_To_Hydrology": 1,
  "Vertical_Distance_To_Hydrology": 1,
  "Horizontal_Distance_To_Roadways": 1,
  "Hillshade_9am": 1,
  "Hillshade_Noon": 1,
  "Hillshade_3pm": 1,
  "Horizontal_Distance_To_Fire_Points": 1,
  "Wilderness_Area": "Rawah",
  "Soil_Type": "C7745"
}
```

## ğŸš¦ Pruebas de Carga con Locust

Locust permite simular mÃºltiples usuarios haciendo peticiones concurrentes a la API.

### ğŸ“œ DefiniciÃ³n de prueba (locustfile.py)

Cada usuario simulado:

- ğŸ” Consulta los modelos disponibles (GET /models)
- ğŸ¯ Selecciona un modelo (POST /select-model)
- ğŸ§® EnvÃ­a una solicitud de predicciÃ³n (POST /predict)
- â±ï¸ Espera entre 1 y 2.5 segundos antes de repetir

### ğŸ³ Uso con Docker Compose

#### ğŸ”§ Levantar todos los servicios

```bash
docker-compose up --build
```

#### ğŸŒ Accesos rÃ¡pidos

- ğŸ“ FastAPI Docs: http://localhost:8000/docs
- ğŸ§ª JupyterLab: http://localhost:8888
- ğŸ“Š Locust UI: http://localhost:8089

## âš–ï¸ Escalamiento y Pruebas de Rendimiento

Se realizaron pruebas de rendimiento utilizando diferentes configuraciones de rÃ©plicas para evaluar el comportamiento del sistema bajo carga. Las pruebas mostraron resultados significativos sobre el impacto de la escalabilidad horizontal en el rendimiento del sistema.

### ğŸ”¬ Hallazgos principales:

1. **ğŸ”´ Sin rÃ©plicas (1 instancia)**:
   - Recursos: 10GB RAM, 0.5 CPU
   - Rendimiento: Solo se logrÃ³ completar con Ã©xito las peticiones GET (mapeo de modelos)
   - Las operaciones POST mÃ¡s intensivas fallaron bajo carga
   - DesempeÃ±o:
      ![alt text](image-5.png)
   - EstadÃ­sticas:
      ![alt text](image-6.png)

2. **ğŸŸ  Con 2 rÃ©plicas**:
   - Recursos por instancia: 5GB RAM, 0.25 CPU (total: 10GB RAM, 0.5 CPU)
   - Rendimiento: Se logrÃ³ completar con Ã©xito las peticiones GET y POST para seleccionar modelos
   - Las peticiones de predicciÃ³n (POST /predict) aÃºn presentaban fallos
   - **Capturas de pantalla**:
     - DesempeÃ±o:
     ![alt text](image.png)
     - EstadÃ­sticas:
     ![alt text](image-1.png)

3. **ğŸŸ¢ Con 4 rÃ©plicas**:
   - Recursos por instancia: 2.5GB RAM, 0.125 CPU (total: 10GB RAM, 0.5 CPU)
   - Rendimiento: Se logrÃ³ completar todo el flujo de trabajo con Ã©xito, incluyendo las operaciones de predicciÃ³n
   - Mejor estabilidad general del sistema
   - **Capturas de pantalla**:
     - DesempeÃ±o:
     ![alt text](image-4.png)
     - EstadÃ­sticas: 
     ![alt text](image-3.png)
     

### ğŸ’¡ Conclusiones:

Las pruebas demostraron que aunque el total de recursos asignados se mantuvo constante (10GB RAM, 0.5 CPU), la distribuciÃ³n de estos recursos en mÃºltiples instancias mÃ¡s pequeÃ±as mejorÃ³ significativamente el rendimiento y la estabilidad del sistema. El escenario con 4 rÃ©plicas mostrÃ³ el mejor comportamiento a pesar de utilizar exactamente los mismos recursos totales que las configuraciones con menos rÃ©plicas. Lo otro que me parece importante mencionar es que se nota una diferencia de comportamientos cuando hay 4 rÃ©plicas y se observan picos de carga.

Una posible hipÃ³tesis para explicar este comportamiento es que, al lanzar mÃºltiples contenedores de Locust simultÃ¡neamente, todos los workers comienzan a generar carga al mismo tiempo. Por ejemplo, si se definen 500 usuarios distribuidos en 5 contenedores, cada worker manejarÃ¡ 100 usuarios que empiezan su actividad sin pausas iniciales, lo que genera un gran pico de trÃ¡fico al comienzo de la prueba. Esta sincronizaciÃ³n podrÃ­a estar influyendo en los picos de carga observados en las pruebas con mÃºltiples rÃ©plicas.

Este hallazgo confirma que para aplicaciones como la API de inferencia de modelos ML, la escalabilidad horizontal (aumentar el nÃºmero de instancias) puede ser mÃ¡s efectiva que la escalabilidad vertical (aumentar los recursos de una Ãºnica instancia).

Las evidencias completas de estas pruebas se encuentran disponibles en la carpeta taller-locust/images/con replicas y taller-locust/images/sin replicas. `taller-locust/images/con replicas` y `taller-locust/images/sin replicas`.

---

## âš ï¸ Importante

  * Para poder almacenar los modelos y experimentos de MLFLOW se debe haber creado el bucket manualmente en MINIO con el nombre mlflows3, al no hacerlo no se registrara la informacion en MLFLOW. 
  * Para poder hacer inferencia de la API por primera vez se debe realizar todo el proceso de ejecucion de los dags debido a que la api requiere del modelo que se genera en el dag 3. Si esto no se aplica entonces la API no se habilitara.

## ğŸ‘¥ Autores

* ğŸ‘¨â€ğŸ’» Luis Frontuso
* ğŸ‘¨â€ğŸ’» Miguel ZuÃ±iga
* ğŸ‘¨â€ğŸ’» Camilo Serrano