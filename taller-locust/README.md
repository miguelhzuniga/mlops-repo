# README para el Cl칰ster de Airflow con CeleryExecutor, Redis y PostgreSQL

Este repositorio configura un entorno de desarrollo local para ejecutar Apache Airflow con CeleryExecutor, Redis como broker de tareas y PostgreSQL como backend de la base de datos. Adem치s, el entorno incluye MinIO para almacenamiento de artefactos, MySQL para almacenar metadata de MLFlow, PgAdmin para monitorear la base de datos de airflow y JupyterLab como ambiente de desarrollo.

---

## Servicios en Docker Compose

El entorno de desarrollo est치 compuesto por varios contenedores Docker que incluyen Airflow, bases de datos, almacenamiento de artefactos y m치s. A continuaci칩n, se describen los servicios principales:

### 1. **Airflow**: Cl칰ster con CeleryExecutor

Airflow se ejecuta utilizando CeleryExecutor, y se conecta a Redis para la gesti칩n de tareas y PostgreSQL para el almacenamiento de metadatos.

- **Airflow Webserver**: Accede a la UI de Airflow en `http://localhost:8080`
- **Airflow Scheduler**: Controla la ejecuci칩n de tareas programadas.
- **Airflow Worker**: Ejecuta las tareas programadas por el scheduler.
- **Airflow Triggerer**: Gestiona trabajos que activan tareas manualmente.

  ![alt text](images/captura_airflow.png)

### 2. **Redis**: Broker de Celery

Redis se usa como broker para las tareas de Celery. Es necesario para la comunicaci칩n entre el `Scheduler` y los `Workers` de Airflow.

### 3. **PostgreSQL**: Backend de Airflow

PostgreSQL se usa como base de datos para almacenar los metadatos de Airflow. Se conecta con los `Scheduler` y `Workers`.

### 4. **MinIO**: Almacenamiento S3

MinIO emula un almacenamiento tipo S3, utilizado para almacenar los artefactos de MLFlow.

- Accede a la consola web de MinIO en `http://localhost:9001` utilizando las credenciales:
  - Usuario: `admin`
  - Contrase침a: `supersecret`

- Se debe crear el bucket para almacenar los artefactos de MLFLOW en la interfaz gr치fica por medio del bot칩n "Create bucket" y este debe llamarse mlflows3 para que mlflow pueda reconocerlo y se guarde la informaci칩n.

![alt text](images/captura_minio.png)

### 5. **MLFlow**: Plataforma de Gesti칩n de Experimentos

MLFlow se utiliza para el seguimiento de experimentos de Machine Learning. Se conecta a MySQL para almacenar metadatos.

- Accede a la interfaz web de MLFlow en `http://localhost:5000`.

![alt text](images/captura_mlflow.png)

### 6. **PgAdmin**: Interfaz de Administraci칩n de PostgreSQL

PgAdmin proporciona una interfaz gr치fica para gestionar la base de datos de PostgreSQL.

- Accede a la interfaz web de PgAdmin en `http://localhost:5050`.
  - Usuario: `admin@example.com`
  - Contrase침a: `admin`
Se debe registrar la base de datos con:
- hostname: postgres
- user: airflow
- password: airflow

Para esto se da click en "Servers">"Register" y se ingresan los datos anteriores. Luego se da "Save". Aparecer치 la base de datos a la cual si se despliega se podr치 dar click derecho y poner "Query tools" y luego hacer consultas como por ejemplo "select * from covertype".

De este modo se puede comprobar que los datos que airflow genera con el dag Cargar_datos.py est치n cargados a la base de datos de Postgresql

![alt text](images/captura_pgadmin.png)

### 7. **MySQL**: Base de Datos de MLFlow

MySQL se usa para almacenar los metadatos de MLFlow. Se conecta con el contenedor de MLFlow.

### 8. **JupyterLab**: Entorno de Desarrollo

JupyterLab proporciona un entorno interactivo para desarrollo y pruebas. Puedes acceder a 칠l en `http://localhost:8888` usando el token `devtoken`.

![alt text](images/captura_jupyter.png)

### 9. **FastAPI (API)**: API de Inferencia

FastAPI proporciona un servidor para exponer endpoints que interact칰an con otros servicios como Airflow y MLFlow. Accede al servidor en `http://localhost:8000/docs`.

Aqui se puede utilizar el mejor modelo generado tras los experimentos de MLFLOW para realizar inferencia.

* Nota: el modelo debe estar en estado de producci칩n en Mlflow y debe llamarse modelo1.

![alt text](images/captura_api.png)

### 10. **FastAPI (API Server)**: Servidor de API

Esta API simula una URL de internet que provee un batch de datos cada 5 segundos, para un total de 10 batches, los cuales ser치n utilizados para entrenar posteriormente el modelo en airflow y registrar los experimentos y el mejor modelo en mlflow. Los datos se almacenan en la base de datos "airflow" dentro de la tabla "covertype".
`http://localhost:80`.

---

## Uso

Para ejecutar los contenedores y configurar el entorno, sigue estos pasos:

IP MV: 10.43.101.202


1. **Construir los contenedores**:

   En el directorio ra칤z del proyecto, ejecuta:

   ```bash
   docker-compose up -d --build
   ```
    Para ver el estatus de los servicios:
   ```bash
   docker-compose ps
   ```
    Para bajar los servicios:
   ```bash
   docker-compose down
   ```

   Para bajar los servicios limpiando todo:
   ```bash
   docker-compose down --volumes --remove-orphans
   ```

2. **Prender dags programados**:

    En airflow existen 4 dags que se ejecutan diariamente desde el 30 de marzo del 2025:
    1. Borrar_datos: limpia la base de datos si existe. Se ejecuta posterior a la generaci칩n del modelo y est치 programado 1 hora despu칠s de el primer dag. 
    2. Cargar_datos: trae los datos consolidados de la api server tarda aproximadamente 50 segundos y est치 programado a las 0 horas.
    3. Entrenamiento_mode: entrena un RandomForest con los datos cargados, el cual est치 programado 2 minutos despu칠s de cargar los datos.
    4. Procesa_data: genera experimentos para encontrar los mejores hiperpar치metros y por ende el mejor modelo que ser치 utilizado posteriormente por el usuario. Se ejecuta 10 minutos despu칠s de cargar los datos.


    * La ejecuci칩n recomendada para efectuar el proceso por completo es ejecutar los dags en el orden en el que est치n enumerados: primero se limpia la base de datos si existe, se cargan los datos, se entrena el modelo y se genera experimentos.

3. **Inferencia en API**:
    Tras la ejecuci칩n de los dags, el usuario ingresar치 a `http://localhost:8000/docs/`, donde podr치 hacer inferencia con el modelo como el siguiente ejemplo:

    1. FastAPI proporciona un servidor para exponer endpoints que interact칰an con otros servicios como Airflow y MLFlow. Accede al servidor en http://localhost:8000/docs.

Aqui se puede utilizar el mejor modelo generado tras los experimentos de MLFLOW para realizar inferencia.

Nota: el modelo debe estar en estado de producci칩n en Mlflow y debe llamarse modelo1.

4. **Prueba de carga con Locust**

---

## 游댋 Endpoints de la API

### `POST /select-model`
Selecciona el modelo que se usar치 para predicci칩n.

```json
{
  "model_name": "modelo1"
}

POST /predict

Realiza una inferencia con el modelo seleccionado.

{
  "Elevation": 1,
  "Aspect": 1,
  "Slope": 1,
  "Horizontal_Distance_To_Hydrology": 1,
  "Vertical_Distance_To_Hydrology": 1,
  "Horizontal_Distance_To_Roadways": 1,
  "Hillshade_9am": 1,
  "Hillshade_Noon": 1,
  "Hillshade_3pm": 1,
  "Horizontal_Distance_To_Fire_Points": 1,
  "Wilderness_Area": "Rawah",
  "Soil_Type": "C7745"
}

游빍 Pruebas de Carga con Locust

Locust permite simular m칰ltiples usuarios haciendo peticiones concurrentes a la API.
游닆 Definici칩n de prueba (locustfile.py)

Cada usuario simulado:

    Consulta los modelos disponibles (GET /models)

    Selecciona un modelo (POST /select-model)

    Env칤a una solicitud de predicci칩n (POST /predict)

    Espera entre 1 y 2.5 segundos antes de repetir

游냡 Uso con Docker Compose
游댢 Levantar todos los servicios

docker-compose up --build

游깷 Accesos r치pidos

    FastAPI Docs: http://localhost:8000/docs

    JupyterLab: http://localhost:8888

    Locust UI: http://localhost:8089

**Importante**
  * Para poder almacenar los modelos y experimentos de MLFLOW se debe haber creado el bucket manualmente en MINIO con el nombre mlflows3, al no hacerlo no se registrara la informacion en MLFLOW. 
  * Para poder hacer inferencia de la API por primera vez se debe realizar todo el proceso de ejecucion de los dags debido a que la api requiere del modelo que se genera en el dag 3. Si esto no se aplica entonces la API no se habilitara.

**Autores:**

* Luis Frontuso
* Miguel Zu침iga
* Camilo Serrano
