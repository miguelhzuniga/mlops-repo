# PredicciÃ³n de la Especie de PingÃ¼inos ğŸ§

Este repositorio contiene un taller en el que se entrena un modelo de Machine Learning para predecir la especie de un pingÃ¼ino usando el dataset **Penguins**. AdemÃ¡s, se crea un API con **FastAPI** para realizar inferencias y se empaqueta todo en un contenedor Docker.

## Contenido del Taller

### Procesamiento y Entrenamiento del Modelo  
Se implementa un script en Python que: 
- Carga los datos del dataset. 
- Realiza la carga, limpieza, transformaciÃ³n, validaciÃ³n, ingenierÃ­a de caracterÃ­sticas y divisiÃ³n preprocesamiento, limpieza y transformaciÃ³n de datos. 
- Entrena un modelo de clasificaciÃ³n para predecir la especie del pingÃ¼ino. 
- Guarda el modelo entrenado para ser usado posteriormente.

### CreaciÃ³n de un API con FastAPI  
Se desarrolla un servicio API que permite: 
- Permite hacer inferencia al modelo entrenado. 
- MÃ©todo que permite seleccionar cual modelo serÃ¡ usado en el proceso de inferencia.

### ContenerizaciÃ³n con Docker  
Se crea una imagen Docker para el API, exponiÃ©ndola en el puerto **8989**.
# ğŸ§ PredicciÃ³n de la Especie de PingÃ¼inos

Este repositorio contiene un taller en el que se entrena un modelo de *Machine Learning* para predecir la especie de un pingÃ¼ino usando el dataset *Penguins*. AdemÃ¡s, se crea un API con *FastAPI* para realizar inferencias y se empaqueta todo en un contenedor *Docker*.  

## ğŸ“Œ Contenido del Taller  

### ğŸ“Š Procesamiento y Entrenamiento del Modelo  
Se implementa un script en Python que:  
- ğŸ“¥ Carga los datos del dataset.  
- ğŸ› ï¸ Realiza la limpieza, transformaciÃ³n, validaciÃ³n e ingenierÃ­a de caracterÃ­sticas.  
- ğŸ“Š Divide los datos en conjuntos de entrenamiento y prueba.  
- ğŸ¤– Entrena dos modelos de clasificaciÃ³n (KNN y RegresiÃ³n logÃ­stica) para predecir la especie del pingÃ¼ino.  
- ğŸ’¾ Guarda los modelos entrenados para su uso posterior.  

### ğŸš€ CreaciÃ³n de un API con FastAPI  
Se desarrolla un servicio API que:  
- ğŸ” Permite hacer inferencias con el modelo entrenado.  
- ğŸ“Œ Incluye un mÃ©todo para seleccionar quÃ© modelo utilizar en el proceso de inferencia.  

### ğŸ³ ContenerizaciÃ³n con Docker  
Se crea una imagen Docker para el API, exponiÃ©ndola en el puerto `8989`.  

Para lograr esto, se desarrolla un script de Bash (`.sh`) que:  
1. ğŸ›‘ Detiene y elimina todos los contenedores existentes.  
2. ğŸ—ï¸ Construye una nueva imagen llamada `"taller"` a partir del `Dockerfile` en el directorio actual.  
3. â–¶ï¸ Ejecuta un nuevo contenedor basado en esa imagen, asignÃ¡ndole el nombre `"taller"` y mapeando el puerto `8000` del host al `8989` del contenedor.  

El `Dockerfile` crea una imagen de *Docker* basada en **Python 3.9**. Copia todos los archivos del directorio actual al contenedor, instala las dependencias listadas en `requirements.txt` sin usar cachÃ©, y finalmente ejecuta la aplicaciÃ³n con *Uvicorn*, iniciando el servidor *FastAPI* desde `main-app.py`, accesible en el puerto `8989` y escuchando en todas las interfaces de red (`0.0.0.0`).  

## ğŸ”¢ Uso del API  
El servidor *FastAPI* permite que un usuario ingrese las siguientes variables del pingÃ¼ino cuya especie quiere predecir:  

- ğŸï¸ `"island"`  
- ğŸ“ `"culmen_length_mm"`  
- ğŸ“ `"culmen_depth_mm"`  
- ğŸ“ `"flipper_length_mm"`  
- âš–ï¸ `"body_mass_g"`  
- â™‚ï¸â™€ï¸ `"sex"`  

Tras recibir estos valores, la API devolverÃ¡ la predicciÃ³n de la especie del pingÃ¼ino. ğŸ§ğŸ” 


##  ğŸ³ ConfiguraciÃ³n con Docker Compose
Este proyecto utiliza docker-compose para gestionar los servicios de la API y JupyterLab de manera eficiente, integrando ademÃ¡s el uso de Uvicorn para manejar las dependencias.

- ğŸ“„ docker-compose.yml
El archivo docker-compose.yml define dos servicios principales:

API (Servidor FastAPI para inferencias)
Construye la imagen desde el directorio ./api.
Expone el puerto 8000 del host, mapeÃ¡ndolo al puerto 80 del contenedor.
Monta los volÃºmenes ./api:/api y ./train:/train para compartir archivos entre el contenedor y el host.
Ejecuta uvicorn para iniciar la API (main-app:app) en 0.0.0.0:80, permitiendo inferencias a travÃ©s de la API.
jupyterlab (Entorno interactivo para entrenamiento y pruebas)
Construye la imagen desde el directorio ./train.
Nombra el contenedor como jupyterlab.
Usa /train como directorio de trabajo.
Monta el volumen ./train:/train para compartir datos entre el contenedor y el host.
Expone el servicio en el puerto 8888, accesible en http://localhost:8888.
Ambos servicios compartirÃ¡n los modelos entrenados porque en ambos se estableciÃ³ volumen: ./train:/train, lo que permite que el modelo guardado en JupyterLab sea consumido por la API para realizar inferencias.


Sigue estos pasos desde la lÃ­nea de comandos BASH:

1. Navega a la ruta taller-02.
2. Ejecuta el comando docker-compose up --build
3. Accede a http://127.0.0.1:8888/lab y ejecuta el notebook "main-train.py" 
4. Si se desea entrenar un nuevo modelo, las modificaciones deben realizarse en el notebook "model_creation". Cada vez que se entrene un nuevo modelo, este estarÃ¡ disponible para ser utilizado en la API.
5. Luego, ingresa a http://localhost:8000/docs.
6. Registra un nÃºmero de Ã­tem.
7. Completa los datos requeridos para realizar la predicciÃ³n, seleccionando el modelo de entre las opciones proporcionadas por el cuerpo de respuesta del GET en /home donde podrÃ¡s ver los modelos disponibles para hacer la predicciÃ³n.

![Ejemplo de predicciÃ³n](images/ejemplo_4.png)


Ejemplo de implementaciÃ³n de la predicciÃ³n:

{
  "item": {
    "island": "Torgersen",
    "culmen_length_mm": 20,
    "culmen_depth_mm": 50,
    "flipper_length_mm": 10,
    "body_mass_g": 5000,
    "sex": "FEMALE",
    "species": null
  },
  "modelo": {
    "modelo": "LogRegCV"
  }
}'

 
La API retornarÃ¡ el campo de species actualizado:
[
  {
    "island": "Torgersen",
    "culmen_length_mm": 20,
    "culmen_depth_mm": 50,
    "flipper_length_mm": 10,
    "body_mass_g": 5000,
    "sex": "FEMALE",
    "species": "Adelie"
  },
  {
    "modelo": "LogRegCV"
  }
]

![Ejemplo de predicciÃ³n](images/ejemplo_1.png)

![Ejemplo de predicciÃ³n](images/ejemplo_2.png)

![Ejemplo de predicciÃ³n](images/ejemplo_3.png)

ğŸ“Œ **Autor:** *Luis, Miguel, Camilo*  
ğŸ“Œ **TecnologÃ­as utilizadas:** Python, FastAPI, Docker compose, Uvicorn  
